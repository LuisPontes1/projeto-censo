{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e127bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de arquivos encontrados: 13\n",
      "Agregados_por_setores_alfabetizacao_BR.parquet\n",
      "Agregados_por_setores_basico_BR_20250417.parquet\n",
      "Agregados_por_setores_caracteristicas_domicilio1_BR.parquet\n",
      "Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.parquet\n",
      "Agregados_por_setores_caracteristicas_domicilio3_BR_20250417.parquet\n",
      "Agregados_por_setores_cor_ou_raca_BR.parquet\n",
      "Agregados_por_setores_demografia_BR.parquet\n",
      "Agregados_por_setores_domicilios_indigenas_BR.parquet\n",
      "Agregados_por_setores_domicilios_quilombolas_BR.parquet\n",
      "Agregados_por_setores_obitos_BR.parquet\n",
      "Agregados_por_setores_parentesco_BR.parquet\n",
      "Agregados_por_setores_pessoas_indigenas_BR.parquet\n",
      "Agregados_por_setores_pessoas_quilombolas_BR.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "SILVER_DIR = \"../data/silver\"\n",
    "parquet_files = glob.glob(os.path.join(SILVER_DIR, \"*.parquet\"))\n",
    "\n",
    "print(f\"Total de arquivos encontrados: {len(parquet_files)}\")\n",
    "for f in parquet_files:\n",
    "    print(os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40552f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Básico: (468099, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_SETOR</th>\n",
       "      <th>SITUACAO</th>\n",
       "      <th>CD_SIT</th>\n",
       "      <th>CD_TIPO</th>\n",
       "      <th>AREA_KM2</th>\n",
       "      <th>CD_REGIAO</th>\n",
       "      <th>NM_REGIAO</th>\n",
       "      <th>CD_UF</th>\n",
       "      <th>NM_UF</th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>...</th>\n",
       "      <th>NM_RGI</th>\n",
       "      <th>CD_CONCURB</th>\n",
       "      <th>NM_CONCURB</th>\n",
       "      <th>total_de_pessoas_v0001</th>\n",
       "      <th>total_de_domicilios_dppo_dppv_dppuo_dpio_dccm_dcsm_v0002</th>\n",
       "      <th>total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003</th>\n",
       "      <th>total_de_domicilios_coletivos_dccm_dcsm_v0004</th>\n",
       "      <th>media_de_moradores_em_domicilios_particulares_ocupados_total_pessoas_em_domicilios_particulares_ocupados_dppo_dpio_v0005</th>\n",
       "      <th>percentual_de_domicilios_particulares_ocupados_imputados_total_dpo_imputados_total_dpo_v0006</th>\n",
       "      <th>total_de_domicilios_particulares_ocupados_dppo_dpio_v0007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539310</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1100015</td>\n",
       "      <td>...</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>928</td>\n",
       "      <td>376</td>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1100015</td>\n",
       "      <td>...</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>556</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1100015</td>\n",
       "      <td>...</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>222</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505448</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1100015</td>\n",
       "      <td>...</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>785</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>1</td>\n",
       "      <td>Norte</td>\n",
       "      <td>11</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1100015</td>\n",
       "      <td>...</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>748</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_SETOR  SITUACAO CD_SIT CD_TIPO  AREA_KM2 CD_REGIAO NM_REGIAO  \\\n",
       "0  110001505000002       NaN      1       0  0.539310         1     Norte   \n",
       "1  110001505000003       NaN      1       0  0.236217         1     Norte   \n",
       "2  110001505000004       NaN      1       0  0.211867         1     Norte   \n",
       "3  110001505000006       NaN      1       0  0.505448         1     Norte   \n",
       "4  110001505000007       NaN      1       0  0.299042         1     Norte   \n",
       "\n",
       "  CD_UF     NM_UF   CD_MUN  ...  NM_RGI CD_CONCURB NM_CONCURB  \\\n",
       "0    11  Rondônia  1100015  ...  Cacoal       None       None   \n",
       "1    11  Rondônia  1100015  ...  Cacoal       None       None   \n",
       "2    11  Rondônia  1100015  ...  Cacoal       None       None   \n",
       "3    11  Rondônia  1100015  ...  Cacoal       None       None   \n",
       "4    11  Rondônia  1100015  ...  Cacoal       None       None   \n",
       "\n",
       "  total_de_pessoas_v0001  \\\n",
       "0                    928   \n",
       "1                    556   \n",
       "2                    222   \n",
       "3                    785   \n",
       "4                    748   \n",
       "\n",
       "  total_de_domicilios_dppo_dppv_dppuo_dpio_dccm_dcsm_v0002  \\\n",
       "0                                                376         \n",
       "1                                                243         \n",
       "2                                                102         \n",
       "3                                                318         \n",
       "4                                                334         \n",
       "\n",
       "  total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003  \\\n",
       "0                                                376            \n",
       "1                                                243            \n",
       "2                                                102            \n",
       "3                                                318            \n",
       "4                                                334            \n",
       "\n",
       "  total_de_domicilios_coletivos_dccm_dcsm_v0004  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "  media_de_moradores_em_domicilios_particulares_ocupados_total_pessoas_em_domicilios_particulares_ocupados_dppo_dpio_v0005  \\\n",
       "0                                                2.8                                                                         \n",
       "1                                                2.7                                                                         \n",
       "2                                                2.6                                                                         \n",
       "3                                                2.8                                                                         \n",
       "4                                                2.6                                                                         \n",
       "\n",
       "  percentual_de_domicilios_particulares_ocupados_imputados_total_dpo_imputados_total_dpo_v0006  \\\n",
       "0                                             0.0923                                             \n",
       "1                                             0.0048                                             \n",
       "2                                             0.0000                                             \n",
       "3                                             0.0000                                             \n",
       "4                                             0.0447                                             \n",
       "\n",
       "  total_de_domicilios_particulares_ocupados_dppo_dpio_v0007  \n",
       "0                                                336         \n",
       "1                                                208         \n",
       "2                                                 85         \n",
       "3                                                282         \n",
       "4                                                291         \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar Dataset Básico (Universo)\n",
    "basico_file = [f for f in parquet_files if 'basico' in f.lower()][0]\n",
    "df_basico = pd.read_parquet(basico_file)\n",
    "print(\"Shape Básico:\", df_basico.shape)\n",
    "df_basico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf47f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD_SETOR', 'SITUACAO', 'CD_SIT', 'CD_TIPO', 'AREA_KM2', 'CD_REGIAO', 'NM_REGIAO', 'CD_UF', 'NM_UF', 'CD_MUN', 'NM_MUN', 'CD_DIST', 'NM_DIST', 'CD_SUBDIST', 'NM_SUBDIST', 'CD_BAIRRO', 'NM_BAIRRO', 'CD_NU', 'NM_NU', 'CD_FCU', 'NM_FCU', 'CD_AGLOM', 'NM_AGLOM', 'CD_RGINT', 'NM_RGINT', 'CD_RGI', 'NM_RGI', 'CD_CONCURB', 'NM_CONCURB', 'total_de_pessoas_v0001', 'total_de_domicilios_dppo_dppv_dppuo_dpio_dccm_dcsm_v0002', 'total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003', 'total_de_domicilios_coletivos_dccm_dcsm_v0004', 'media_de_moradores_em_domicilios_particulares_ocupados_total_pessoas_em_domicilios_particulares_ocupados_dppo_dpio_v0005', 'percentual_de_domicilios_particulares_ocupados_imputados_total_dpo_imputados_total_dpo_v0006', 'total_de_domicilios_particulares_ocupados_dppo_dpio_v0007']\n"
     ]
    }
   ],
   "source": [
    "print(df_basico.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df0a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Demografia: (458772, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_setor</th>\n",
       "      <th>quantidade_de_moradores_v01006</th>\n",
       "      <th>sexo_masculino_v01007</th>\n",
       "      <th>sexo_feminino_v01008</th>\n",
       "      <th>sexo_masculino_0_a_4_anos_v01009</th>\n",
       "      <th>sexo_masculino_5_a_9_anos_v01010</th>\n",
       "      <th>sexo_masculino_10_a_14_anos_v01011</th>\n",
       "      <th>sexo_masculino_15_a_19_anos_v01012</th>\n",
       "      <th>sexo_masculino_20_a_24_anos_v01013</th>\n",
       "      <th>sexo_masculino_25_a_29_anos_v01014</th>\n",
       "      <th>...</th>\n",
       "      <th>5_a_9_anos_v01032</th>\n",
       "      <th>10_a_14_anos_v01033</th>\n",
       "      <th>15_a_19_anos_v01034</th>\n",
       "      <th>20_a_24_anos_v01035</th>\n",
       "      <th>25_a_29_anos_v01036</th>\n",
       "      <th>30_a_39_anos_v01037</th>\n",
       "      <th>40_a_49_anos_v01038</th>\n",
       "      <th>50_a_59_anos_v01039</th>\n",
       "      <th>60_a_69_anos_v01040</th>\n",
       "      <th>70_anos_ou_mais_v01041</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>928.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>556.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>222.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>785.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>748.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_setor  quantidade_de_moradores_v01006  sexo_masculino_v01007  \\\n",
       "0  110001505000002                           928.0                  428.0   \n",
       "1  110001505000003                           556.0                  270.0   \n",
       "2  110001505000004                           222.0                  108.0   \n",
       "3  110001505000006                           785.0                  408.0   \n",
       "4  110001505000007                           748.0                  373.0   \n",
       "\n",
       "   sexo_feminino_v01008  sexo_masculino_0_a_4_anos_v01009  \\\n",
       "0                 500.0                              30.0   \n",
       "1                 286.0                              15.0   \n",
       "2                 114.0                               5.0   \n",
       "3                 377.0                              36.0   \n",
       "4                 375.0                              28.0   \n",
       "\n",
       "   sexo_masculino_5_a_9_anos_v01010  sexo_masculino_10_a_14_anos_v01011  \\\n",
       "0                              39.0                                24.0   \n",
       "1                              20.0                                20.0   \n",
       "2                               4.0                                 9.0   \n",
       "3                              33.0                                34.0   \n",
       "4                              25.0                                33.0   \n",
       "\n",
       "   sexo_masculino_15_a_19_anos_v01012  sexo_masculino_20_a_24_anos_v01013  \\\n",
       "0                                44.0                                36.0   \n",
       "1                                19.0                                30.0   \n",
       "2                                14.0                                 7.0   \n",
       "3                                41.0                                42.0   \n",
       "4                                27.0                                24.0   \n",
       "\n",
       "   sexo_masculino_25_a_29_anos_v01014  ...  5_a_9_anos_v01032  \\\n",
       "0                                25.0  ...               68.0   \n",
       "1                                20.0  ...               36.0   \n",
       "2                                 5.0  ...               11.0   \n",
       "3                                27.0  ...               63.0   \n",
       "4                                31.0  ...               52.0   \n",
       "\n",
       "   10_a_14_anos_v01033  15_a_19_anos_v01034  20_a_24_anos_v01035  \\\n",
       "0                 62.0                 88.0                 68.0   \n",
       "1                 47.0                 38.0                 47.0   \n",
       "2                 15.0                 26.0                 11.0   \n",
       "3                 61.0                 75.0                 71.0   \n",
       "4                 54.0                 52.0                 51.0   \n",
       "\n",
       "   25_a_29_anos_v01036  30_a_39_anos_v01037  40_a_49_anos_v01038  \\\n",
       "0                 58.0                144.0                129.0   \n",
       "1                 44.0                 83.0                 95.0   \n",
       "2                 11.0                 33.0                 37.0   \n",
       "3                 53.0                124.0                 92.0   \n",
       "4                 61.0                110.0                116.0   \n",
       "\n",
       "   50_a_59_anos_v01039  60_a_69_anos_v01040  70_anos_ou_mais_v01041  \n",
       "0                124.0                 66.0                    53.0  \n",
       "1                 48.0                 47.0                    34.0  \n",
       "2                 25.0                 23.0                    17.0  \n",
       "3                 88.0                 57.0                    40.0  \n",
       "4                 93.0                 63.0                    46.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar Dataset Demografia\n",
    "demo_file = [f for f in parquet_files if 'demografia' in f.lower()][0]\n",
    "df_demo = pd.read_parquet(demo_file)\n",
    "print(\"Shape Demografia:\", df_demo.shape)\n",
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b29cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD_setor', 'quantidade_de_moradores_v01006', 'sexo_masculino_v01007', 'sexo_feminino_v01008', 'sexo_masculino_0_a_4_anos_v01009', 'sexo_masculino_5_a_9_anos_v01010', 'sexo_masculino_10_a_14_anos_v01011', 'sexo_masculino_15_a_19_anos_v01012', 'sexo_masculino_20_a_24_anos_v01013', 'sexo_masculino_25_a_29_anos_v01014', 'sexo_masculino_30_a_39_anos_v01015', 'sexo_masculino_40_a_49_anos_v01016', 'sexo_masculino_50_a_59_anos_v01017', 'sexo_masculino_60_a_69_anos_v01018', 'sexo_masculino_70_anos_ou_mais_v01019', 'sexo_feminino_0_a_4_anos_v01020', 'sexo_feminino_5_a_9_anos_v01021', 'sexo_feminino_10_a_14_anos_v01022', 'sexo_feminino_15_a_19_anos_v01023', 'sexo_feminino_20_a_24_anos_v01024', 'sexo_feminino_25_a_29_anos_v01025', 'sexo_feminino_30_a_39_anos_v01026', 'sexo_feminino_40_a_49_anos_v01027', 'sexo_feminino_50_a_59_anos_v01028', 'sexo_feminino_60_a_69_anos_v01029', 'sexo_feminino_70_anos_ou_mais_v01030', '0_a_4_anos_v01031', '5_a_9_anos_v01032', '10_a_14_anos_v01033', '15_a_19_anos_v01034', '20_a_24_anos_v01035', '25_a_29_anos_v01036', '30_a_39_anos_v01037', '40_a_49_anos_v01038', '50_a_59_anos_v01039', '60_a_69_anos_v01040', '70_anos_ou_mais_v01041']\n"
     ]
    }
   ],
   "source": [
    "print(df_demo.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60bedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Básico Unique CD_SETOR: 468099\n",
      "Demografia Unique CD_SETOR: 458772\n",
      "Shape Merged: (458772, 72)\n"
     ]
    }
   ],
   "source": [
    "# Join pelo CD_SETOR\n",
    "# Normalizar nome da coluna chave\n",
    "if 'CD_setor' in df_demo.columns:\n",
    "    df_demo.rename(columns={'CD_setor': 'CD_SETOR'}, inplace=True)\n",
    "\n",
    "# Verificar se CD_SETOR é único em ambos\n",
    "print(\"Básico Unique CD_SETOR:\", df_basico['CD_SETOR'].nunique())\n",
    "print(\"Demografia Unique CD_SETOR:\", df_demo['CD_SETOR'].nunique())\n",
    "\n",
    "# Merge\n",
    "df_merged = pd.merge(df_basico, df_demo, on='CD_SETOR', how='inner', suffixes=('', '_demo'))\n",
    "print(\"Shape Merged:\", df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ff253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas Homens: ['sexo_masculino_v01007']\n",
      "Colunas Mulheres: ['sexo_feminino_v01008']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_SETOR</th>\n",
       "      <th>NM_MUN</th>\n",
       "      <th>razao_sexo</th>\n",
       "      <th>densidade_demografica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1720.716575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>2353.762952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1047.829153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1553.078588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>2501.317539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_SETOR                 NM_MUN  razao_sexo  densidade_demografica\n",
       "0  110001505000002  Alta Floresta D'Oeste    0.856000            1720.716575\n",
       "1  110001505000003  Alta Floresta D'Oeste    0.944056            2353.762952\n",
       "2  110001505000004  Alta Floresta D'Oeste    0.947368            1047.829153\n",
       "3  110001505000006  Alta Floresta D'Oeste    1.082228            1553.078588\n",
       "4  110001505000007  Alta Floresta D'Oeste    0.994667            2501.317539"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de Feature Engineering\n",
    "# Razão de Sexo: Homens / Mulheres\n",
    "# Precisamos identificar as colunas de homens e mulheres no dataset de demografia.\n",
    "# Vamos listar as colunas do df_demo para encontrar.\n",
    "cols_homens = [c for c in df_demo.columns if 'sexo_masculino' in c and 'anos' not in c]\n",
    "cols_mulheres = [c for c in df_demo.columns if 'sexo_feminino' in c and 'anos' not in c]\n",
    "\n",
    "print(\"Colunas Homens:\", cols_homens)\n",
    "print(\"Colunas Mulheres:\", cols_mulheres)\n",
    "\n",
    "# Supondo que encontramos as colunas totais (sem faixa etária)\n",
    "col_homem_total = cols_homens[0]\n",
    "col_mulher_total = cols_mulheres[0]\n",
    "\n",
    "# Calcular Razão de Sexo\n",
    "# Adicionar 1e-6 para evitar divisão por zero\n",
    "df_merged['razao_sexo'] = df_merged[col_homem_total] / (df_merged[col_mulher_total] + 1e-6)\n",
    "\n",
    "# Densidade Demográfica (População / Área)\n",
    "# População total está no basico (total_de_pessoas_v0001)\n",
    "# Área está em AREA_KM2 (precisa garantir que é float)\n",
    "\n",
    "# Converter AREA_KM2 para float se necessário (já deve ter sido tratado, mas vamos garantir)\n",
    "if df_merged['AREA_KM2'].dtype == 'object':\n",
    "     df_merged['AREA_KM2'] = df_merged['AREA_KM2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "df_merged['densidade_demografica'] = df_merged['total_de_pessoas_v0001'] / df_merged['AREA_KM2']\n",
    "\n",
    "# Visualizar resultados\n",
    "df_merged[['CD_SETOR', 'NM_MUN', 'razao_sexo', 'densidade_demografica']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ba03c",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "Agora temos um pipeline funcional para:\n",
    "1. Ingerir dados brutos (CSV) -> Silver (Parquet) com nomes legíveis.\n",
    "2. Carregar e unificar tabelas diferentes (Básico + Demografia).\n",
    "3. Criar features analíticas (Razão de Sexo, Densidade).\n",
    "\n",
    "O próximo passo lógico seria integrar com a **Malha Geográfica** (geobr) para permitir visualização em mapa e análises espaciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31b154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de Idade: ['sexo_masculino_0_a_4_anos_v01009', 'sexo_masculino_5_a_9_anos_v01010', 'sexo_masculino_10_a_14_anos_v01011', 'sexo_masculino_15_a_19_anos_v01012', 'sexo_masculino_20_a_24_anos_v01013', 'sexo_masculino_25_a_29_anos_v01014', 'sexo_masculino_30_a_39_anos_v01015', 'sexo_masculino_40_a_49_anos_v01016', 'sexo_masculino_50_a_59_anos_v01017', 'sexo_masculino_60_a_69_anos_v01018']\n",
      "\n",
      "Procurando variáveis de Renda/Rendimento no Dicionário:\n",
      "Nenhuma variável de renda encontrada nos arquivos baixados (baseado no dicionário).\n"
     ]
    }
   ],
   "source": [
    "# Analisar colunas de Idade disponíveis no dataset Demografia\n",
    "cols_idade = [c for c in df_demo.columns if 'anos' in c]\n",
    "print(\"Colunas de Idade:\", cols_idade[:10]) # Mostrar as primeiras\n",
    "\n",
    "# Verificar se temos dados de Renda\n",
    "# Vamos procurar no dicionário (carregado anteriormente ou recarregar)\n",
    "DICT_FILE = \"../data/raw/dicionario_de_dados_agregados_por_setores_censitarios_20250417.xlsx\"\n",
    "xls = pd.ExcelFile(DICT_FILE)\n",
    "\n",
    "print(\"\\nProcurando variáveis de Renda/Rendimento no Dicionário:\")\n",
    "found_renda = False\n",
    "for sheet in xls.sheet_names:\n",
    "    if 'Siglas' in sheet: continue\n",
    "    df_dict_sheet = pd.read_excel(DICT_FILE, sheet_name=sheet)\n",
    "    if 'Descrição' in df_dict_sheet.columns:\n",
    "        renda_vars = df_dict_sheet[df_dict_sheet['Descrição'].str.contains('Rendimento|Renda', case=False, na=False)]\n",
    "        if not renda_vars.empty:\n",
    "            print(f\"\\n--- Aba: {sheet} ---\")\n",
    "            print(renda_vars[['Variável', 'Descrição']].head())\n",
    "            found_renda = True\n",
    "\n",
    "if not found_renda:\n",
    "    print(\"Nenhuma variável de renda encontrada nos arquivos baixados (baseado no dicionário).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a5757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "População Total Calculada: 202389481.0\n",
      "População Total Original: 203080756\n",
      "Diferença: -691275.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_SETOR</th>\n",
       "      <th>NM_MUN</th>\n",
       "      <th>NM_UF</th>\n",
       "      <th>AREA_KM2</th>\n",
       "      <th>total_de_pessoas_v0001</th>\n",
       "      <th>total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003</th>\n",
       "      <th>pop_0_19</th>\n",
       "      <th>pop_20_69</th>\n",
       "      <th>pop_70_plus</th>\n",
       "      <th>razao_sexo</th>\n",
       "      <th>densidade_demografica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.539310</td>\n",
       "      <td>928</td>\n",
       "      <td>376</td>\n",
       "      <td>286.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1720.716575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>556</td>\n",
       "      <td>243</td>\n",
       "      <td>158.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>2353.762952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>222</td>\n",
       "      <td>102</td>\n",
       "      <td>65.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1047.829153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.505448</td>\n",
       "      <td>785</td>\n",
       "      <td>318</td>\n",
       "      <td>260.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1553.078588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>748</td>\n",
       "      <td>334</td>\n",
       "      <td>208.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>2501.317539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_SETOR                 NM_MUN     NM_UF  AREA_KM2  \\\n",
       "0  110001505000002  Alta Floresta D'Oeste  Rondônia  0.539310   \n",
       "1  110001505000003  Alta Floresta D'Oeste  Rondônia  0.236217   \n",
       "2  110001505000004  Alta Floresta D'Oeste  Rondônia  0.211867   \n",
       "3  110001505000006  Alta Floresta D'Oeste  Rondônia  0.505448   \n",
       "4  110001505000007  Alta Floresta D'Oeste  Rondônia  0.299042   \n",
       "\n",
       "   total_de_pessoas_v0001  \\\n",
       "0                     928   \n",
       "1                     556   \n",
       "2                     222   \n",
       "3                     785   \n",
       "4                     748   \n",
       "\n",
       "   total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003  pop_0_19  \\\n",
       "0                                                376               286.0   \n",
       "1                                                243               158.0   \n",
       "2                                                102                65.0   \n",
       "3                                                318               260.0   \n",
       "4                                                334               208.0   \n",
       "\n",
       "   pop_20_69  pop_70_plus  razao_sexo  densidade_demografica  \n",
       "0      589.0         53.0    0.856000            1720.716575  \n",
       "1      364.0         34.0    0.944056            2353.762952  \n",
       "2      140.0         17.0    0.947368            1047.829153  \n",
       "3      485.0         40.0    1.082228            1553.078588  \n",
       "4      494.0         46.0    0.994667            2501.317539  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir estratégia de agregação de Idade (Corrigida e Segura)\n",
    "# Faixas disponíveis:\n",
    "# 0-4, 5-9, 10-14, 15-19\n",
    "# 20-24, 25-29, 30-39, 40-49, 50-59, 60-69\n",
    "# 70+\n",
    "\n",
    "# Função auxiliar para somar colunas de forma segura\n",
    "def sum_age_columns(df, patterns):\n",
    "    cols_to_sum = []\n",
    "    for pat in patterns:\n",
    "        # Encontrar a coluna exata que corresponde ao padrão (excluindo sexo)\n",
    "        # O padrão deve ser parte do nome, ex: '0_a_4_anos'\n",
    "        for c in df.columns:\n",
    "            if 'sexo_' in c: continue\n",
    "            if pat in c:\n",
    "                cols_to_sum.append(c)\n",
    "    \n",
    "    # Remover duplicatas se houver\n",
    "    cols_to_sum = list(set(cols_to_sum))\n",
    "    return df[cols_to_sum].sum(axis=1)\n",
    "\n",
    "# 1. Jovens (0 a 19 anos) - Aproximação para \"até 18\"\n",
    "patterns_0_19 = ['0_a_4_anos', '5_a_9_anos', '10_a_14_anos', '15_a_19_anos']\n",
    "df_merged['pop_0_19'] = sum_age_columns(df_merged, patterns_0_19)\n",
    "\n",
    "# 2. Adultos (20 a 69 anos) - Aproximação para \"18 a 65\"\n",
    "# Nota: A faixa 60-69 é indivisível, então optamos por incluir até 69.\n",
    "patterns_20_69 = [\n",
    "    '20_a_24_anos', '25_a_29_anos', '30_a_39_anos', \n",
    "    '40_a_49_anos', '50_a_59_anos', '60_a_69_anos'\n",
    "]\n",
    "df_merged['pop_20_69'] = sum_age_columns(df_merged, patterns_20_69)\n",
    "\n",
    "# 3. Idosos (70 anos ou mais) - Aproximação para \"> 65\"\n",
    "patterns_70_plus = ['70_anos_ou_mais']\n",
    "df_merged['pop_70_plus'] = sum_age_columns(df_merged, patterns_70_plus)\n",
    "\n",
    "# Verificar totais\n",
    "df_merged['pop_total_calc'] = df_merged['pop_0_19'] + df_merged['pop_20_69'] + df_merged['pop_70_plus']\n",
    "print(\"População Total Calculada:\", df_merged['pop_total_calc'].sum())\n",
    "print(\"População Total Original:\", df_merged['total_de_pessoas_v0001'].sum())\n",
    "print(\"Diferença:\", df_merged['pop_total_calc'].sum() - df_merged['total_de_pessoas_v0001'].sum())\n",
    "\n",
    "# Selecionar colunas finais\n",
    "cols_to_keep = [\n",
    "    'CD_SETOR', 'NM_MUN', 'NM_UF', 'AREA_KM2', \n",
    "    'total_de_pessoas_v0001', 'total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003',\n",
    "    'pop_0_19', 'pop_20_69', 'pop_70_plus',\n",
    "    'razao_sexo', 'densidade_demografica'\n",
    "]\n",
    "\n",
    "df_final = df_merged[cols_to_keep].copy()\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a56abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de idade ignorada: []\n"
     ]
    }
   ],
   "source": [
    "# Verificar colunas de idade ignorada ou sem declaração\n",
    "ignored_cols = [c for c in df_merged.columns if 'ignorada' in c or 'sem_declaracao' in c]\n",
    "print(\"Colunas de idade ignorada:\", ignored_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298c42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicionário carregado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Carregar dicionário\n",
    "# Ajustando caminho relativo pois estamos na pasta notebooks/\n",
    "dict_path = '../data/raw/dicionario_de_dados_agregados_por_setores_censitarios_20250417.xlsx'\n",
    "if os.path.exists(dict_path):\n",
    "    dicionario = pd.read_excel(dict_path, sheet_name=None)\n",
    "    print(\"Dicionário carregado com sucesso.\")\n",
    "else:\n",
    "    print(f\"Arquivo de dicionário não encontrado em: {dict_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d890909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhuma variável de renda/rendimento encontrada nos dicionários atuais.\n"
     ]
    }
   ],
   "source": [
    "# Investigação sobre Renda\n",
    "# O usuário pediu dados de Renda. Vamos varrer o dicionário em busca de termos relacionados.\n",
    "search_terms = ['renda', 'rendimento', 'salario', 'salário', 'domiciliar', 'responsavel']\n",
    "\n",
    "found_vars = []\n",
    "# O dicionário é um dict de DataFrames (sheet_name -> df)\n",
    "# Vamos iterar todas as abas\n",
    "for sheet, df_dict in dicionario.items():\n",
    "    # Geralmente as colunas de descrição são 'Nome da Variável' ou 'Descrição'\n",
    "    # Vamos procurar em todas as colunas de texto\n",
    "    for col in df_dict.columns:\n",
    "        if df_dict[col].dtype == 'object':\n",
    "            for term in search_terms:\n",
    "                matches = df_dict[df_dict[col].astype(str).str.contains(term, case=False, na=False)]\n",
    "                if not matches.empty:\n",
    "                    for idx, row in matches.iterrows():\n",
    "                        found_vars.append((sheet, row.values))\n",
    "\n",
    "if found_vars:\n",
    "    print(f\"Encontradas {len(found_vars)} menções a renda/rendimento:\")\n",
    "    for item in found_vars[:10]: # Mostrar apenas os primeiros\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"Nenhuma variável de renda/rendimento encontrada nos dicionários atuais.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55484341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\projetos\\projeto-censo\\notebooks\n",
      "['01_exploracao_inicial.ipynb', '02_feature_engineering.ipynb']\n",
      "Data folder found in parent directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "if os.path.exists('../data'):\n",
    "    print(\"Data folder found in parent directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be48e47",
   "metadata": {},
   "source": [
    "## Análise de Renda\n",
    "\n",
    "**Status:** Dados de Renda não encontrados nos arquivos de \"Agregados por Setores Censitários\" disponíveis no FTP do IBGE até o momento (Abril 2025).\n",
    "- Foram verificados os dicionários e os arquivos CSV.\n",
    "- Variáveis buscadas: \"Renda\", \"Rendimento\", \"Salário\", \"Responsável\".\n",
    "- Resultado: Nenhuma variável correspondente encontrada.\n",
    "\n",
    "**Ação:** Seguiremos apenas com as variáveis demográficas (Idade, Sexo, Densidade) por enquanto. A análise de renda ficará pendente até a liberação dos dados de \"Rendimento\" ou \"Entorno\" pelo IBGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32bf7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvo em: ../data/silver/censo_2022_agregado_idade.parquet\n"
     ]
    }
   ],
   "source": [
    "# Salvar dataset processado\n",
    "output_path = '../data/silver/censo_2022_agregado_idade.parquet'\n",
    "df_final.to_parquet(output_path, index=False)\n",
    "print(f\"Dataset salvo em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c19463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALFABETIZACAO ---\n",
      "Shape: (458772, 363)\n",
      "Exemplo de colunas: ['CD_setor', '15_a_19_anos_v00644', '20_a_24_anos_v00645', '25_a_29_anos_v00646', '30_a_34_anos_v00647', '35_a_39_anos_v00648', '40_a_44_anos_v00649', '45_a_49_anos_v00650', '50_a_54_anos_v00651', '55_a_59_anos_v00652'] ...\n",
      "------------------------------\n",
      "--- DOMICILIO1 ---\n",
      "Shape: (458772, 90)\n",
      "Exemplo de colunas: ['CD_setor', 'domicilios_particulares_permanentes_ocupados_v00001', 'domicilios_particulares_improvisados_ocupados_v00002', 'unidades_de_habitacao_em_domicilios_coletivos_com_morador_v00003', 'domicilios_particulares_permanentes_ocupados_v00004', 'domicilios_particulares_permanentes_ocupados_quantidade_de_moradores_v00005', 'domicilios_particulares_improvisados_ocupados_quantidade_de_moradores_v00006', 'domicilios_coletivos_com_morador_quantidade_de_moradores_v00007', 'domicilios_particulares_permanentes_ocupados_quantidade_de_criancas_de_zero_a_nove_anos_de_idade_v00008', 'domicilios_particulares_improvisados_ocupados_quantidade_de_criancas_de_zero_a_nove_anos_de_idade_v00009'] ...\n",
      "------------------------------\n",
      "--- DOMICILIO2 ---\n",
      "Shape: (458772, 407)\n",
      "Exemplo de colunas: ['setor', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00090', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00091', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_amarela_v00092', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_parda_v00093', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_indigena_v00094', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00095', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00096', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_amarela_v00097', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_parda_v00098'] ...\n",
      "------------------------------\n",
      "--- COR_RACA ---\n",
      "Shape: (458772, 96)\n",
      "Exemplo de colunas: ['cor_ou_raca_e_branca_v01317', 'cor_ou_raca_e_preta_v01318', 'cor_ou_raca_e_amarela_v01319', 'cor_ou_raca_e_parda_v01320', 'cor_ou_raca_e_indigena_v01321', 'sexo_masculino_cor_ou_raca_e_branca_v01322', 'sexo_masculino_cor_ou_raca_e_preta_v01323', 'sexo_masculino_cor_ou_raca_e_amarela_v01324', 'sexo_masculino_cor_ou_raca_e_parda_v01325', 'sexo_masculino_cor_ou_raca_e_indigena_v01326'] ...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- EXPLORAÇÃO DE NOVOS CONTEXTOS ---\n",
    "# Vamos carregar amostras dos outros datasets para entender as variáveis disponíveis.\n",
    "# Datasets de interesse para Feature Engineering \"Legal\":\n",
    "# 1. Alfabetização (Educação)\n",
    "# 2. Características do Domicílio (Saneamento = Proxy de Renda)\n",
    "# 3. Cor ou Raça (Demografia detalhada)\n",
    "\n",
    "files_to_explore = {\n",
    "    'alfabetizacao': 'Agregados_por_setores_alfabetizacao_BR.parquet',\n",
    "    'domicilio1': 'Agregados_por_setores_caracteristicas_domicilio1_BR.parquet',\n",
    "    'domicilio2': 'Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.parquet',\n",
    "    'cor_raca': 'Agregados_por_setores_cor_ou_raca_BR.parquet'\n",
    "}\n",
    "\n",
    "data_dir = '../data/silver'\n",
    "\n",
    "for name, filename in files_to_explore.items():\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"--- {name.upper()} ---\")\n",
    "        df_temp = pd.read_parquet(path)\n",
    "        print(f\"Shape: {df_temp.shape}\")\n",
    "        # Mostrar colunas que não são chaves primárias (CD_SETOR, etc)\n",
    "        cols = [c for c in df_temp.columns if c not in ['CD_SETOR', 'NM_MUN', 'NM_UF', 'AREA_KM2']]\n",
    "        print(f\"Exemplo de colunas: {cols[:10]} ...\") # Mostrar as 10 primeiras variáveis\n",
    "        print(\"-\" * 30)\n",
    "    else:\n",
    "        print(f\"Arquivo {filename} não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55aff19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SANEAMENTO ===\n",
      "Sheet: Dicionário não PCT | Keyword: abastecimento\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "Sheet: Dicionário não PCT | Keyword: lixo\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "Sheet: Dicionário PCT - Indígenas | Keyword: abastecimento\n",
      "     Tipo      Tema\n",
      "Domicílio Indígenas\n",
      "Domicílio Indígenas\n",
      "Domicílio Indígenas\n",
      "...\n",
      "Sheet: Dicionário PCT - Indígenas | Keyword: lixo\n",
      "     Tipo      Tema\n",
      "Domicílio Indígenas\n",
      "Domicílio Indígenas\n",
      "Domicílio Indígenas\n",
      "...\n",
      "Sheet: Dicionário PCT - Quilombolas | Keyword: abastecimento\n",
      "     Tipo        Tema\n",
      "Domicílio Quilombolas\n",
      "Domicílio Quilombolas\n",
      "Domicílio Quilombolas\n",
      "...\n",
      "Sheet: Dicionário PCT - Quilombolas | Keyword: lixo\n",
      "     Tipo        Tema\n",
      "Domicílio Quilombolas\n",
      "Domicílio Quilombolas\n",
      "Domicílio Quilombolas\n",
      "...\n",
      "\n",
      "\n",
      "=== ALFABETIZACAO ===\n",
      "\n",
      "\n",
      "=== RACA ===\n",
      "Sheet: Dicionário não PCT | Keyword: branca\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "Sheet: Dicionário não PCT | Keyword: preta\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "Sheet: Dicionário não PCT | Keyword: parda\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "Sheet: Dicionário não PCT | Keyword: amarela\n",
      "     Tipo                                   Tema\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "Domicílio Características do Domicílio - Parte 2\n",
      "...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Buscar variáveis no dicionário para os temas de interesse\n",
    "\n",
    "themes = {\n",
    "    'Saneamento': ['abastecimento', 'esgotamento', 'lixo', 'sanitario'],\n",
    "    'Alfabetizacao': ['alfabetizado'],\n",
    "    'Raca': ['branca', 'preta', 'parda', 'amarela', 'indigena']\n",
    "}\n",
    "\n",
    "for theme, keywords in themes.items():\n",
    "    print(f\"=== {theme.upper()} ===\")\n",
    "    for sheet, df_dict in dicionario.items():\n",
    "        # Procurar nas colunas de texto\n",
    "        for col in df_dict.columns:\n",
    "            if df_dict[col].dtype == 'object':\n",
    "                for kw in keywords:\n",
    "                    matches = df_dict[df_dict[col].astype(str).str.contains(kw, case=False, na=False)]\n",
    "                    if not matches.empty:\n",
    "                        # Mostrar apenas colunas relevantes: Identificador e Descrição\n",
    "                        # Assumindo que a primeira coluna é ID e a segunda é Descrição (ajustar conforme visualização)\n",
    "                        print(f\"Sheet: {sheet} | Keyword: {kw}\")\n",
    "                        print(matches.iloc[:3, :2].to_string(index=False)) # Mostrar top 3 matches\n",
    "                        print(\"...\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9ba22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DOMICILIO 2: Água, Esgoto, Lixo ---\n",
      "Colunas (Amostra): ['domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_parda_v00093', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_indigena_v00094', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00095', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00096', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_amarela_v00097', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_parda_v00098', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_indigena_v00099', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00100', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00101', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_amarela_v00102', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_parda_v00103', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_indigena_v00104', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_sexo_da_pessoa_responsavel_pelo_domicilio_e_masculino_v00105', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_sexo_da_pessoa_responsavel_pelo_domicilio_e_feminino_v00106', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_sexo_da_pessoa_responsavel_pelo_domicilio_e_masculino_v00107', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_sexo_da_pessoa_responsavel_pelo_domicilio_e_feminino_v00108', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_sexo_da_pessoa_responsavel_pelo_domicilio_e_masculino_v00109', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_sexo_da_pessoa_responsavel_pelo_domicilio_e_feminino_v00110', 'domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111', 'domicilios_particulares_permanentes_ocupados_utiliza_poco_profundo_ou_artesiano_v00112']\n",
      "Água (Dom2): ['domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111', 'domicilios_particulares_permanentes_ocupados_utiliza_poco_profundo_ou_artesiano_v00112', 'domicilios_particulares_permanentes_ocupados_utiliza_poco_raso_freatico_ou_cacimba_v00113', 'domicilios_particulares_permanentes_ocupados_utiliza_agua_da_chuva_armazenada_v00116', 'domicilios_particulares_permanentes_ocupados_utiliza_outra_forma_de_abastecimento_de_agua_v00118']\n",
      "Esgoto (Dom2): ['domicilios_particulares_permanentes_ocupados_1_banheiro_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00232', 'domicilios_particulares_permanentes_ocupados_2_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00233', 'domicilios_particulares_permanentes_ocupados_3_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00234', 'domicilios_particulares_permanentes_ocupados_4_ou_mais_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00235', 'domicilios_particulares_permanentes_ocupados_apenas_sanitario_ou_buraco_para_dejecoes_inclusive_os_localizados_no_terreno_v00237']\n",
      "Lixo (Dom2): ['domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397', 'domicilios_particulares_permanentes_ocupados_lixo_depositado_em_cacamba_de_servico_de_limpeza_v00398', 'domicilios_particulares_permanentes_ocupados_lixo_queimado_na_propriedade_v00399', 'domicilios_particulares_permanentes_ocupados_lixo_enterrado_na_propriedade_v00400', 'domicilios_particulares_permanentes_ocupados_lixo_jogado_em_terreno_baldio_encosta_ou_area_publica_v00401']\n",
      "\n",
      "--- ALFABETIZAÇÃO (Verificação) ---\n",
      "Totais (Exemplos): []\n"
     ]
    }
   ],
   "source": [
    "# Inspecionar colunas diretamente nos arquivos Parquet\n",
    "\n",
    "# 1. Saneamento (Verificar Domicilio 2 também)\n",
    "path_dom2 = os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.parquet')\n",
    "df_dom2 = pd.read_parquet(path_dom2)\n",
    "\n",
    "print(\"--- DOMICILIO 2: Água, Esgoto, Lixo ---\")\n",
    "# Vamos listar as primeiras 20 colunas para entender o padrão\n",
    "print(\"Colunas (Amostra):\", df_dom2.columns[4:24].tolist())\n",
    "\n",
    "# Tentar palavras chave mais amplas\n",
    "cols_agua_2 = [c for c in df_dom2.columns if 'agua' in c or 'rede' in c or 'poco' in c]\n",
    "cols_esgoto_2 = [c for c in df_dom2.columns if 'esgoto' in c or 'sanitario' in c or 'fossa' in c]\n",
    "cols_lixo_2 = [c for c in df_dom2.columns if 'lixo' in c or 'coletado' in c]\n",
    "\n",
    "print(\"Água (Dom2):\", cols_agua_2[:5])\n",
    "print(\"Esgoto (Dom2):\", cols_esgoto_2[:5])\n",
    "print(\"Lixo (Dom2):\", cols_lixo_2[:5])\n",
    "\n",
    "# 2. Alfabetização (Já encontramos, vamos definir os totais)\n",
    "# Precisamos do Total de Pessoas na faixa etária para calcular a taxa.\n",
    "# O arquivo de alfabetização tem o total de pessoas ou só alfabetizadas?\n",
    "print(\"\\n--- ALFABETIZAÇÃO (Verificação) ---\")\n",
    "cols_total_alfa = [c for c in df_alfa.columns if 'total' in c or 'pessoas_de' in c]\n",
    "print(\"Totais (Exemplos):\", cols_total_alfa[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90b4d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas df_alfa (início): Index(['CD_setor', '15_a_19_anos_v00644', '20_a_24_anos_v00645',\n",
      "       '25_a_29_anos_v00646', '30_a_34_anos_v00647'],\n",
      "      dtype='object')\n",
      "Colunas Alfabetização encontradas: ['pessoas_alfabetizadas_15_a_19_anos_v00748', 'pessoas_alfabetizadas_20_a_24_anos_v00749', 'pessoas_alfabetizadas_25_a_29_anos_v00750', 'pessoas_alfabetizadas_30_a_34_anos_v00751', 'pessoas_alfabetizadas_35_a_39_anos_v00752']\n",
      "CD_SETOR não encontrado nas colunas de df_alfa. Tentando reset_index.\n",
      "ERRO: CD_SETOR ainda não encontrado em df_alfa. Colunas disponíveis: Index(['index', 'CD_setor', '15_a_19_anos_v00644', '20_a_24_anos_v00645',\n",
      "       '25_a_29_anos_v00646', '30_a_34_anos_v00647', '35_a_39_anos_v00648',\n",
      "       '40_a_44_anos_v00649', '45_a_49_anos_v00650', '50_a_54_anos_v00651',\n",
      "       ...\n",
      "       'domicilios_particulares_permanentes_ocupados_netos_as_ou_bisnetos_as_pessoas_alfabetizadas_sexo_feminino_15_anos_ou_mais_v00999',\n",
      "       'domicilios_particulares_permanentes_ocupados_irmaos_ou_irmas_pessoas_alfabetizadas_sexo_masculino_15_anos_ou_mais_v01000',\n",
      "       'domicilios_particulares_permanentes_ocupados_irmaos_ou_irmas_pessoas_alfabetizadas_sexo_feminino_15_anos_ou_mais_v01001',\n",
      "       'domicilios_particulares_permanentes_ocupados_outros_parentes_pessoas_alfabetizadas_sexo_masculino_15_anos_ou_mais_v01002',\n",
      "       'domicilios_particulares_permanentes_ocupados_outros_parentes_pessoas_alfabetizadas_sexo_feminino_15_anos_ou_mais_v01003',\n",
      "       'domicilios_particulares_permanentes_ocupados_convivente_pessoas_alfabetizadas_sexo_masculino_15_anos_ou_mais_v01004',\n",
      "       'domicilios_particulares_permanentes_ocupados_convivente_pessoas_alfabetizadas_sexo_feminino_15_anos_ou_mais_v01005',\n",
      "       'total_alfabetizados', 'total_pessoas_alfa_base', 'taxa_alfabetizacao'],\n",
      "      dtype='object', length=367)\n",
      "Novas features adicionadas: Taxa Alfabetização, % Branca, % Preta, % Parda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_SETOR</th>\n",
       "      <th>NM_MUN</th>\n",
       "      <th>NM_UF</th>\n",
       "      <th>AREA_KM2</th>\n",
       "      <th>total_de_pessoas_v0001</th>\n",
       "      <th>total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003</th>\n",
       "      <th>pop_0_19</th>\n",
       "      <th>pop_20_69</th>\n",
       "      <th>pop_70_plus</th>\n",
       "      <th>razao_sexo</th>\n",
       "      <th>densidade_demografica</th>\n",
       "      <th>pct_branca</th>\n",
       "      <th>pct_preta</th>\n",
       "      <th>pct_parda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.539310</td>\n",
       "      <td>928</td>\n",
       "      <td>376</td>\n",
       "      <td>286.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1720.716575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>556</td>\n",
       "      <td>243</td>\n",
       "      <td>158.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>2353.762952</td>\n",
       "      <td>0.339928</td>\n",
       "      <td>0.044964</td>\n",
       "      <td>0.604317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>222</td>\n",
       "      <td>102</td>\n",
       "      <td>65.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1047.829153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.505448</td>\n",
       "      <td>785</td>\n",
       "      <td>318</td>\n",
       "      <td>260.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>1553.078588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>748</td>\n",
       "      <td>334</td>\n",
       "      <td>208.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>2501.317539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_SETOR                 NM_MUN     NM_UF  AREA_KM2  \\\n",
       "0  110001505000002  Alta Floresta D'Oeste  Rondônia  0.539310   \n",
       "1  110001505000003  Alta Floresta D'Oeste  Rondônia  0.236217   \n",
       "2  110001505000004  Alta Floresta D'Oeste  Rondônia  0.211867   \n",
       "3  110001505000006  Alta Floresta D'Oeste  Rondônia  0.505448   \n",
       "4  110001505000007  Alta Floresta D'Oeste  Rondônia  0.299042   \n",
       "\n",
       "   total_de_pessoas_v0001  \\\n",
       "0                     928   \n",
       "1                     556   \n",
       "2                     222   \n",
       "3                     785   \n",
       "4                     748   \n",
       "\n",
       "   total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003  pop_0_19  \\\n",
       "0                                                376               286.0   \n",
       "1                                                243               158.0   \n",
       "2                                                102                65.0   \n",
       "3                                                318               260.0   \n",
       "4                                                334               208.0   \n",
       "\n",
       "   pop_20_69  pop_70_plus  razao_sexo  densidade_demografica  pct_branca  \\\n",
       "0      589.0         53.0    0.856000            1720.716575         NaN   \n",
       "1      364.0         34.0    0.944056            2353.762952    0.339928   \n",
       "2      140.0         17.0    0.947368            1047.829153         NaN   \n",
       "3      485.0         40.0    1.082228            1553.078588         NaN   \n",
       "4      494.0         46.0    0.994667            2501.317539         NaN   \n",
       "\n",
       "   pct_preta  pct_parda  \n",
       "0        NaN        NaN  \n",
       "1   0.044964   0.604317  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- FEATURE ENGINEERING: NOVOS CONTEXTOS ---\n",
    "\n",
    "# Função para somar colunas por padrão (reutilizando lógica)\n",
    "def sum_cols(df, pattern):\n",
    "    cols = [c for c in df.columns if pattern in c and 'sexo_' not in c]\n",
    "    return df[cols].sum(axis=1)\n",
    "\n",
    "# 1. ALFABETIZAÇÃO\n",
    "# Carregar dataset\n",
    "df_alfa = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_alfabetizacao_BR.parquet'))\n",
    "\n",
    "# Debug: Verificar colunas\n",
    "print(\"Colunas df_alfa (início):\", df_alfa.columns[:5])\n",
    "\n",
    "# Identificar colunas de Alfabetizados (15 anos ou mais)\n",
    "cols_alfa_15_plus = [c for c in df_alfa.columns if 'pessoas_alfabetizadas_' in c and '5_anos' not in c and '6_a_14' not in c]\n",
    "print(\"Colunas Alfabetização encontradas:\", cols_alfa_15_plus[:5])\n",
    "\n",
    "df_alfa['total_alfabetizados'] = df_alfa[cols_alfa_15_plus].sum(axis=1)\n",
    "\n",
    "# Total de Pessoas na mesma faixa\n",
    "cols_total_alfa = [c for c in df_alfa.columns if 'pessoas_de_' in c and 'alfabetizadas' not in c]\n",
    "df_alfa['total_pessoas_alfa_base'] = df_alfa[cols_total_alfa].sum(axis=1)\n",
    "\n",
    "# Calcular Taxa\n",
    "df_alfa['taxa_alfabetizacao'] = df_alfa['total_alfabetizados'] / df_alfa['total_pessoas_alfa_base']\n",
    "\n",
    "# Merge com df_final\n",
    "# Garantir que CD_SETOR é coluna\n",
    "if 'CD_SETOR' not in df_alfa.columns:\n",
    "    print(\"CD_SETOR não encontrado nas colunas de df_alfa. Tentando reset_index.\")\n",
    "    df_alfa = df_alfa.reset_index()\n",
    "\n",
    "# Verificar novamente\n",
    "if 'CD_SETOR' in df_alfa.columns:\n",
    "    df_final = df_final.merge(df_alfa[['CD_SETOR', 'taxa_alfabetizacao']], on='CD_SETOR', how='left')\n",
    "else:\n",
    "    print(\"ERRO: CD_SETOR ainda não encontrado em df_alfa. Colunas disponíveis:\", df_alfa.columns)\n",
    "\n",
    "# 2. RAÇA / COR\n",
    "df_raca = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_cor_ou_raca_BR.parquet'))\n",
    "\n",
    "# Colunas específicas\n",
    "def get_col_by_keyword(df, keyword):\n",
    "    cols = [c for c in df.columns if keyword in c and 'sexo_' not in c]\n",
    "    return cols[0] if cols else None\n",
    "\n",
    "col_branca = get_col_by_keyword(df_raca, 'cor_ou_raca_e_branca')\n",
    "col_preta = get_col_by_keyword(df_raca, 'cor_ou_raca_e_preta')\n",
    "col_parda = get_col_by_keyword(df_raca, 'cor_ou_raca_e_parda')\n",
    "col_amarela = get_col_by_keyword(df_raca, 'cor_ou_raca_e_amarela')\n",
    "col_indigena = get_col_by_keyword(df_raca, 'cor_ou_raca_e_indigena')\n",
    "\n",
    "# Calcular percentuais\n",
    "total_raca = df_raca[col_branca] + df_raca[col_preta] + df_raca[col_parda] + df_raca[col_amarela] + df_raca[col_indigena]\n",
    "df_raca['pct_branca'] = df_raca[col_branca] / total_raca\n",
    "df_raca['pct_preta'] = df_raca[col_preta] / total_raca\n",
    "df_raca['pct_parda'] = df_raca[col_parda] / total_raca\n",
    "\n",
    "# Merge\n",
    "if 'CD_SETOR' not in df_raca.columns:\n",
    "    df_raca = df_raca.reset_index()\n",
    "\n",
    "df_final = df_final.merge(df_raca[['CD_SETOR', 'pct_branca', 'pct_preta', 'pct_parda']], on='CD_SETOR', how='left')\n",
    "\n",
    "print(\"Novas features adicionadas: Taxa Alfabetização, % Branca, % Preta, % Parda\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c6e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Colunas Domicilio 2 (Busca por palavras-chave) ---\n",
      "Água (77): ['domicilios_particulares_permanentes_ocupados_utiliza_agua_da_chuva_armazenada_v00116', 'domicilios_particulares_permanentes_ocupados_utiliza_outra_forma_de_abastecimento_de_agua_v00118', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_utiliza_agua_da_chuva_armazenada_v00124']\n",
      "Esgoto (165): ['domicilios_particulares_permanentes_ocupados_1_banheiro_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00232', 'domicilios_particulares_permanentes_ocupados_2_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00233', 'domicilios_particulares_permanentes_ocupados_3_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00234']\n",
      "Lixo (66): ['domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397', 'domicilios_particulares_permanentes_ocupados_lixo_depositado_em_cacamba_de_servico_de_limpeza_v00398', 'domicilios_particulares_permanentes_ocupados_lixo_queimado_na_propriedade_v00399']\n"
     ]
    }
   ],
   "source": [
    "# --- SANEAMENTO ---\n",
    "# Investigar Domicilio 2 para variáveis de saneamento\n",
    "df_dom2 = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.parquet'))\n",
    "\n",
    "print(\"--- Colunas Domicilio 2 (Busca por palavras-chave) ---\")\n",
    "cols_agua = [c for c in df_dom2.columns if 'agua' in c]\n",
    "cols_esgoto = [c for c in df_dom2.columns if 'esgoto' in c or 'sanitario' in c]\n",
    "cols_lixo = [c for c in df_dom2.columns if 'lixo' in c]\n",
    "\n",
    "print(f\"Água ({len(cols_agua)}):\", cols_agua[:3])\n",
    "print(f\"Esgoto ({len(cols_esgoto)}):\", cols_esgoto[:3])\n",
    "print(f\"Lixo ({len(cols_lixo)}):\", cols_lixo[:3])\n",
    "\n",
    "# Se não encontrar, tentar Domicilio 1 novamente com busca mais ampla\n",
    "if not cols_agua:\n",
    "    print(\"\\nTentando Domicilio 1...\")\n",
    "    df_dom1 = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio1_BR.parquet'))\n",
    "    cols_agua = [c for c in df_dom1.columns if 'agua' in c]\n",
    "    print(f\"Água Dom1 ({len(cols_agua)}):\", cols_agua[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e66688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Água Rede Geral: ['domicilios_particulares_permanentes_ocupados_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00463', 'domicilios_particulares_permanentes_ocupados_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00464', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00465', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00466', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00467']\n",
      "Esgoto Rede/Fossa: ['domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309', 'domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_ligada_a_rede_v00310', 'domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_nao_ligada_a_rede_v00311', 'domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_rudimentar_ou_buraco_v00312', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00317']\n",
      "Lixo Coletado: ['domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00403', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00409', 'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00415', 'domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00421']\n",
      "Possíveis Totais: []\n"
     ]
    }
   ],
   "source": [
    "# Refinar colunas de Saneamento\n",
    "\n",
    "# Água: Rede Geral\n",
    "cols_agua_rede = [c for c in cols_agua if 'rede_geral' in c]\n",
    "print(\"Água Rede Geral:\", cols_agua_rede[:5])\n",
    "\n",
    "# Esgoto: Rede Geral ou Fossa\n",
    "cols_esgoto_rede = [c for c in cols_esgoto if 'rede_geral' in c or 'fossa' in c]\n",
    "print(\"Esgoto Rede/Fossa:\", cols_esgoto_rede[:5])\n",
    "\n",
    "# Lixo: Coletado\n",
    "cols_lixo_coletado = [c for c in cols_lixo if 'coletado' in c]\n",
    "print(\"Lixo Coletado:\", cols_lixo_coletado[:5])\n",
    "\n",
    "# Total de Domicílios (Denominador)\n",
    "# Podemos usar o total do arquivo Basico (v0003) ou procurar um total neste arquivo.\n",
    "# Geralmente 'domicilios_particulares_permanentes_ocupados_vXXXX'\n",
    "cols_total_dom = [c for c in df_dom2.columns if 'domicilios_particulares_permanentes_ocupados_v' in c]\n",
    "# Pegar o primeiro que parece ser o total geral (menor sufixo ou nome mais curto)\n",
    "print(\"Possíveis Totais:\", cols_total_dom[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "707d4bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas df_dom2 (Início): Index(['level_0', 'index', 'setor',\n",
      "       'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00090',\n",
      "       'domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00091'],\n",
      "      dtype='object')\n",
      "Renomeando 'setor' para 'CD_SETOR'\n",
      "Colunas encontradas: Água=domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111, Esgoto=domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309, Lixo=domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397\n",
      "Colunas a mergear do Dom2: ['domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309', 'domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397', 'CD_SETOR', 'domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111']\n",
      "Feature pct_agua_rede calculada.\n",
      "Feature pct_esgoto_rede calculada.\n",
      "Feature pct_lixo_coletado calculada.\n",
      "Features de Saneamento processadas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_SETOR</th>\n",
       "      <th>NM_MUN</th>\n",
       "      <th>NM_UF</th>\n",
       "      <th>AREA_KM2</th>\n",
       "      <th>total_de_pessoas_v0001</th>\n",
       "      <th>total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003</th>\n",
       "      <th>pop_0_19</th>\n",
       "      <th>pop_20_69</th>\n",
       "      <th>pop_70_plus</th>\n",
       "      <th>razao_sexo</th>\n",
       "      <th>...</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_x</th>\n",
       "      <th>pct_lixo_coletado</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_x</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_y</th>\n",
       "      <th>pct_esgoto_rede</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_y</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397</th>\n",
       "      <th>domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111</th>\n",
       "      <th>pct_agua_rede</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110001505000002</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.539310</td>\n",
       "      <td>928</td>\n",
       "      <td>376</td>\n",
       "      <td>286.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.183511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110001505000003</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>556</td>\n",
       "      <td>243</td>\n",
       "      <td>158.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.843621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.065844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110001505000004</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>222</td>\n",
       "      <td>102</td>\n",
       "      <td>65.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.480392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110001505000006</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.505448</td>\n",
       "      <td>785</td>\n",
       "      <td>318</td>\n",
       "      <td>260.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.082228</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.550314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110001505000007</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Rondônia</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>748</td>\n",
       "      <td>334</td>\n",
       "      <td>208.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.449102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CD_SETOR                 NM_MUN     NM_UF  AREA_KM2  \\\n",
       "0  110001505000002  Alta Floresta D'Oeste  Rondônia  0.539310   \n",
       "1  110001505000003  Alta Floresta D'Oeste  Rondônia  0.236217   \n",
       "2  110001505000004  Alta Floresta D'Oeste  Rondônia  0.211867   \n",
       "3  110001505000006  Alta Floresta D'Oeste  Rondônia  0.505448   \n",
       "4  110001505000007  Alta Floresta D'Oeste  Rondônia  0.299042   \n",
       "\n",
       "   total_de_pessoas_v0001  \\\n",
       "0                     928   \n",
       "1                     556   \n",
       "2                     222   \n",
       "3                     785   \n",
       "4                     748   \n",
       "\n",
       "   total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003  pop_0_19  \\\n",
       "0                                                376               286.0   \n",
       "1                                                243               158.0   \n",
       "2                                                102                65.0   \n",
       "3                                                318               260.0   \n",
       "4                                                334               208.0   \n",
       "\n",
       "   pop_20_69  pop_70_plus  razao_sexo  ...  \\\n",
       "0      589.0         53.0    0.856000  ...   \n",
       "1      364.0         34.0    0.944056  ...   \n",
       "2      140.0         17.0    0.947368  ...   \n",
       "3      485.0         40.0    1.082228  ...   \n",
       "4      494.0         46.0    0.994667  ...   \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_x  \\\n",
       "0                                                NaN                                                         \n",
       "1                                                NaN                                                         \n",
       "2                                                NaN                                                         \n",
       "3                                                NaN                                                         \n",
       "4                                                NaN                                                         \n",
       "\n",
       "   pct_lixo_coletado  \\\n",
       "0           0.813830   \n",
       "1           0.843621   \n",
       "2           0.823529   \n",
       "3           0.792453   \n",
       "4           0.850299   \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_x  \\\n",
       "0                                                NaN                                                                                                     \n",
       "1                                                NaN                                                                                                     \n",
       "2                                                NaN                                                                                                     \n",
       "3                                                NaN                                                                                                     \n",
       "4                                                NaN                                                                                                     \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_y  \\\n",
       "0                                                NaN                                                         \n",
       "1                                                NaN                                                         \n",
       "2                                                NaN                                                         \n",
       "3                                                NaN                                                         \n",
       "4                                                NaN                                                         \n",
       "\n",
       "   pct_esgoto_rede  \\\n",
       "0              0.0   \n",
       "1              0.0   \n",
       "2              0.0   \n",
       "3              NaN   \n",
       "4              0.0   \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_y  \\\n",
       "0                                                NaN                                                                                                     \n",
       "1                                                NaN                                                                                                     \n",
       "2                                                NaN                                                                                                     \n",
       "3                                                NaN                                                                                                     \n",
       "4                                                NaN                                                                                                     \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309  \\\n",
       "0                                                0.0                                                                                                   \n",
       "1                                                0.0                                                                                                   \n",
       "2                                                0.0                                                                                                   \n",
       "3                                                NaN                                                                                                   \n",
       "4                                                0.0                                                                                                   \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397  \\\n",
       "0                                              306.0                                                       \n",
       "1                                              205.0                                                       \n",
       "2                                               84.0                                                       \n",
       "3                                              252.0                                                       \n",
       "4                                              284.0                                                       \n",
       "\n",
       "   domicilios_particulares_permanentes_ocupados_utiliza_rede_geral_de_distribuicao_v00111  \\\n",
       "0                                               69.0                                        \n",
       "1                                               16.0                                        \n",
       "2                                               49.0                                        \n",
       "3                                              175.0                                        \n",
       "4                                              150.0                                        \n",
       "\n",
       "   pct_agua_rede  \n",
       "0       0.183511  \n",
       "1       0.065844  \n",
       "2       0.480392  \n",
       "3       0.550314  \n",
       "4       0.449102  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular Features de Saneamento (Final - Debug 2)\n",
    "\n",
    "# Garantir tipos compatíveis\n",
    "if 'CD_SETOR' in df_final.columns:\n",
    "    df_final['CD_SETOR'] = df_final['CD_SETOR'].astype(str)\n",
    "\n",
    "# Debug: Inspecionar df_dom2\n",
    "print(\"Colunas df_dom2 (Início):\", df_dom2.columns[:5])\n",
    "\n",
    "# Garantir CD_SETOR em df_dom2\n",
    "if 'CD_SETOR' not in df_dom2.columns:\n",
    "    # Caso explícito visto no output anterior: 'setor'\n",
    "    if 'setor' in df_dom2.columns:\n",
    "        print(\"Renomeando 'setor' para 'CD_SETOR'\")\n",
    "        df_dom2 = df_dom2.rename(columns={'setor': 'CD_SETOR'})\n",
    "    elif 'CD_setor' in df_dom2.columns:\n",
    "        df_dom2 = df_dom2.rename(columns={'CD_setor': 'CD_SETOR'})\n",
    "    elif df_dom2.index.name == 'CD_SETOR':\n",
    "        df_dom2 = df_dom2.reset_index()\n",
    "    else:\n",
    "        # Tentar resetar index e ver se aparece\n",
    "        df_dom2 = df_dom2.reset_index()\n",
    "        if 'index' in df_dom2.columns:\n",
    "             # Verificar se parece um código\n",
    "             sample = str(df_dom2['index'].iloc[0])\n",
    "             if len(sample) >= 15 and sample.isdigit():\n",
    "                 print(\"Recuperado CD_SETOR do index.\")\n",
    "                 df_dom2 = df_dom2.rename(columns={'index': 'CD_SETOR'})\n",
    "             else:\n",
    "                 # Tentar primeira coluna\n",
    "                 first_col = df_dom2.columns[0]\n",
    "                 sample = str(df_dom2[first_col].iloc[0])\n",
    "                 if len(sample) >= 15 and sample.isdigit():\n",
    "                     print(f\"Recuperado CD_SETOR da coluna {first_col}\")\n",
    "                     df_dom2 = df_dom2.rename(columns={first_col: 'CD_SETOR'})\n",
    "\n",
    "if 'CD_SETOR' in df_dom2.columns:\n",
    "    df_dom2['CD_SETOR'] = df_dom2['CD_SETOR'].astype(str)\n",
    "else:\n",
    "    print(\"ERRO: CD_SETOR não encontrado em df_dom2. Features de saneamento podem falhar.\")\n",
    "\n",
    "# Colunas identificadas (Baseado no Dicionário não PCT)\n",
    "# V00111: Domicílios Particulares Permanentes Ocupados, Utiliza rede geral de distribuição\n",
    "# V00309: Esgoto Rede Geral ou Pluvial\n",
    "# V00397: Lixo Coletado\n",
    "\n",
    "# Função auxiliar para encontrar coluna pelo código (independente do prefixo longo)\n",
    "def find_col_by_code(df, code):\n",
    "    # Tenta encontrar coluna que termina com o código (ex: _v00111)\n",
    "    # O código pode ser 'v00111' ou 'V00111'\n",
    "    code_lower = code.lower()\n",
    "    for c in df.columns:\n",
    "        if c.lower().endswith(f\"_{code_lower}\") or c.lower() == code_lower:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_agua_rede = find_col_by_code(df_dom2, 'v00111')\n",
    "col_esgoto_rede = find_col_by_code(df_dom2, 'v00309')\n",
    "col_lixo_coletado = find_col_by_code(df_dom2, 'v00397')\n",
    "\n",
    "print(f\"Colunas encontradas: Água={col_agua_rede}, Esgoto={col_esgoto_rede}, Lixo={col_lixo_coletado}\")\n",
    "\n",
    "# Merge Dom2 (Água, Esgoto e Lixo estão todos no Dom2 agora)\n",
    "cols_dom2_merge = ['CD_SETOR']\n",
    "if col_agua_rede: cols_dom2_merge.append(col_agua_rede)\n",
    "if col_esgoto_rede: cols_dom2_merge.append(col_esgoto_rede)\n",
    "if col_lixo_coletado: cols_dom2_merge.append(col_lixo_coletado)\n",
    "\n",
    "# Remover duplicatas\n",
    "cols_dom2_merge = list(set(cols_dom2_merge))\n",
    "\n",
    "print(f\"Colunas a mergear do Dom2: {cols_dom2_merge}\")\n",
    "# Remover colunas se já existirem no df_final para evitar sufixos _x _y\n",
    "cols_to_drop = [c for c in cols_dom2_merge if c in df_final.columns and c != 'CD_SETOR']\n",
    "if cols_to_drop:\n",
    "    df_final = df_final.drop(columns=cols_to_drop)\n",
    "\n",
    "if 'CD_SETOR' in df_dom2.columns:\n",
    "    df_final = df_final.merge(df_dom2[cols_dom2_merge], on='CD_SETOR', how='left')\n",
    "\n",
    "    # Calcular indicadores\n",
    "    denom = df_final['total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003']\n",
    "\n",
    "    if col_agua_rede and col_agua_rede in df_final.columns:\n",
    "        df_final['pct_agua_rede'] = df_final[col_agua_rede] / denom\n",
    "        print(\"Feature pct_agua_rede calculada.\")\n",
    "    else:\n",
    "        print(\"Variável de Água não calculada.\")\n",
    "\n",
    "    if col_esgoto_rede and col_esgoto_rede in df_final.columns:\n",
    "        df_final['pct_esgoto_rede'] = df_final[col_esgoto_rede] / denom\n",
    "        print(\"Feature pct_esgoto_rede calculada.\")\n",
    "\n",
    "    if col_lixo_coletado and col_lixo_coletado in df_final.columns:\n",
    "        df_final['pct_lixo_coletado'] = df_final[col_lixo_coletado] / denom\n",
    "        print(\"Feature pct_lixo_coletado calculada.\")\n",
    "\n",
    "    print(\"Features de Saneamento processadas.\")\n",
    "else:\n",
    "    print(\"Pular Saneamento (CD_SETOR ausente).\")\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "374e3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ÁGUA (Rede) ---\n",
      "domicilios_particulares_permanentes_ocupados_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00463\n",
      "domicilios_particulares_permanentes_ocupados_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00464\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00465\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00466\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00467\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00468\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_v00469\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_v00470\n",
      "domicilios_particulares_permanentes_ocupados_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_branca_v00471\n",
      "domicilios_particulares_permanentes_ocupados_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_cor_ou_raca_da_pessoa_responsavel_pelo_domicilio_e_preta_v00472\n",
      "\n",
      "--- ESGOTO (Rede) ---\n",
      "domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309\n",
      "domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_ligada_a_rede_v00310\n",
      "domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_nao_ligada_a_rede_v00311\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00317\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_ligada_a_rede_v00318\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_nao_ligada_a_rede_v00319\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00325\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_ligada_a_rede_v00326\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_de_vila_ou_em_condominio_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_fossa_septica_ou_fossa_filtro_nao_ligada_a_rede_v00327\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_apartamento_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00333\n"
     ]
    }
   ],
   "source": [
    "# Debug: Listar colunas de Água e Esgoto (Filtradas)\n",
    "cols_agua_rede_debug = [c for c in df_dom2.columns if 'agua' in c and 'rede' in c]\n",
    "cols_esgoto_rede_debug = [c for c in df_dom2.columns if ('esgoto' in c or 'sanitario' in c) and 'rede' in c]\n",
    "\n",
    "print(\"--- ÁGUA (Rede) ---\")\n",
    "for c in cols_agua_rede_debug[:10]:\n",
    "    print(c)\n",
    "\n",
    "print(\"\\n--- ESGOTO (Rede) ---\")\n",
    "for c in cols_esgoto_rede_debug[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12b90da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset enriquecido salvo em: ../data/silver/censo_2022_agregado_completo.parquet\n",
      "Colunas finais: ['CD_SETOR', 'NM_MUN', 'NM_UF', 'AREA_KM2', 'total_de_pessoas_v0001', 'total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003', 'pop_0_19', 'pop_20_69', 'pop_70_plus', 'razao_sexo', 'densidade_demografica', 'pct_branca', 'pct_preta', 'pct_parda', 'domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_x', 'pct_lixo_coletado', 'domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_x', 'domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397_y', 'pct_esgoto_rede', 'domicilios_particulares_permanentes_ocupados_destinacao_do_esgoto_do_banheiro_ou_sanitario_ou_buraco_para_dejecoes_e_rede_geral_ou_pluvial_v00309_y', 'domicilios_particulares_permanentes_ocupados_lixo_coletado_no_domicilio_por_servico_de_limpeza_v00397']\n"
     ]
    }
   ],
   "source": [
    "# Salvar Dataset Enriquecido Final\n",
    "output_path_enriched = '../data/silver/censo_2022_agregado_completo.parquet'\n",
    "df_final.to_parquet(output_path_enriched, index=False)\n",
    "print(f\"Dataset enriquecido salvo em: {output_path_enriched}\")\n",
    "print(\"Colunas finais:\", df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83ce2209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando Domicilio 1...\n",
      "Assumindo que a coluna 'CD_setor' é o CD_SETOR\n",
      "Gerando 89 novas features relativas...\n",
      "\n",
      "Processando Domicilio 2...\n",
      "Assumindo que a coluna 'setor' é o CD_SETOR\n",
      "Gerando 406 novas features relativas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando Domicilio 3...\n",
      "Assumindo que a coluna 'setor' é o CD_SETOR\n",
      "Gerando 148 novas features relativas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
      "C:\\Users\\lfrpo\\AppData\\Local\\Temp\\ipykernel_19332\\2504587753.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_features[feat_name] = df_work[col] / df_work[denominator_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consolidando features...\n",
      "Shape final: (458772, 664)\n",
      "Colunas finais (Amostra): ['pct_dom3_lixo_jogado_em_terreno_baldio_encosta_ou_area_publica_pessoas_de_sexo_feminino_no_domicilio_v0634', 'pct_dom3_outro_destino_do_lixo_pessoas_de_sexo_feminino_no_domicilio_v0635', 'pct_dom3_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_quantidade_de_moradores_v0636', 'pct_dom3_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_quantidade_de_moradores_v0637', 'pct_dom3_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_quantidade_de_criancas_de_zero_a_nove_anos_de_idade_v0638', 'pct_dom3_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_quantidade_de_criancas_de_zero_a_nove_anos_de_idade_v0639', 'pct_dom3_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_pessoas_de_sexo_masculino_no_domicilio_v0640', 'pct_dom3_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_pessoas_de_sexo_masculino_no_domicilio_v0641', 'pct_dom3_domicilio_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_mas_utiliza_principalmente_outra_forma_pessoas_de_sexo_feminino_no_domicilio_v0642', 'pct_dom3_domicilio_nao_possui_ligacao_a_rede_geral_de_distribuicao_de_agua_pessoas_de_sexo_feminino_no_domicilio_v0643']\n"
     ]
    }
   ],
   "source": [
    "# --- MASSIVE FEATURE ENGINEERING (Correção de Chaves - Debug) ---\n",
    "\n",
    "# Função para garantir CD_SETOR\n",
    "def ensure_cd_setor(df):\n",
    "    # Verificar se CD_SETOR já existe\n",
    "    if 'CD_SETOR' in df.columns:\n",
    "        df['CD_SETOR'] = df['CD_SETOR'].astype(str)\n",
    "        return df\n",
    "    \n",
    "    # Verificar se está no index\n",
    "    # Às vezes o index não tem nome, ou tem nome 'CD_SETOR'\n",
    "    if df.index.name == 'CD_SETOR':\n",
    "        df = df.reset_index()\n",
    "        df['CD_SETOR'] = df['CD_SETOR'].astype(str)\n",
    "        return df\n",
    "        \n",
    "    # Se o index não tem nome, mas é o código\n",
    "    # Vamos resetar o index e ver o que acontece\n",
    "    df_reset = df.reset_index()\n",
    "    \n",
    "    # Se criou uma coluna 'index' ou 'level_0'\n",
    "    if 'index' in df_reset.columns:\n",
    "        # Verificar se parece um código de setor (15 dígitos)\n",
    "        sample = str(df_reset['index'].iloc[0])\n",
    "        if len(sample) >= 15 and sample.isdigit():\n",
    "            df_reset = df_reset.rename(columns={'index': 'CD_SETOR'})\n",
    "            df_reset['CD_SETOR'] = df_reset['CD_SETOR'].astype(str)\n",
    "            return df_reset\n",
    "            \n",
    "    # Se a primeira coluna for o código (às vezes acontece)\n",
    "    first_col = df.columns[0]\n",
    "    sample = str(df[first_col].iloc[0])\n",
    "    if len(sample) >= 15 and sample.isdigit():\n",
    "        print(f\"Assumindo que a coluna '{first_col}' é o CD_SETOR\")\n",
    "        df = df.rename(columns={first_col: 'CD_SETOR'})\n",
    "        df['CD_SETOR'] = df['CD_SETOR'].astype(str)\n",
    "        return df\n",
    "\n",
    "    print(\"AVISO: CD_SETOR não encontrado no DataFrame. Colunas:\", df.columns[:5])\n",
    "    return df\n",
    "\n",
    "# Função para gerar features relativas (Percentuais) automaticamente\n",
    "def generate_relative_features(df_target, df_base, denominator_col, prefix='pct_'):\n",
    "    # Garantir chaves\n",
    "    df_target = ensure_cd_setor(df_target)\n",
    "    df_base = ensure_cd_setor(df_base)\n",
    "    \n",
    "    if 'CD_SETOR' not in df_target.columns:\n",
    "        print(\"Pular dataset: CD_SETOR ausente.\")\n",
    "        return pd.DataFrame() # Retorna vazio se falhar\n",
    "\n",
    "    # Merge temporário para alinhar linhas\n",
    "    df_work = df_target.merge(df_base[['CD_SETOR', denominator_col]], on='CD_SETOR', how='left')\n",
    "    \n",
    "    new_features = pd.DataFrame()\n",
    "    new_features['CD_SETOR'] = df_work['CD_SETOR']\n",
    "    \n",
    "    # Identificar colunas numéricas (excluindo chaves e o próprio denominador)\n",
    "    cols_to_process = [c for c in df_target.columns if c not in ['CD_SETOR', 'NM_MUN', 'NM_UF', 'AREA_KM2', denominator_col]]\n",
    "    # Filtrar apenas numéricas\n",
    "    cols_to_process = [c for c in cols_to_process if pd.api.types.is_numeric_dtype(df_target[c])]\n",
    "    \n",
    "    print(f\"Gerando {len(cols_to_process)} novas features relativas...\")\n",
    "    \n",
    "    for col in cols_to_process:\n",
    "        # Tentar encurtar o nome da coluna\n",
    "        short_name = col.replace('domicilios_particulares_permanentes_ocupados_', '')\n",
    "        short_name = short_name.replace('pessoas_residentes_em_domicilios_particulares_permanentes_ocupados_', '')\n",
    "        short_name = short_name.replace('v0', 'v') \n",
    "        \n",
    "        feat_name = f\"{prefix}{short_name}\"\n",
    "        \n",
    "        # Calcular percentual\n",
    "        new_features[feat_name] = df_work[col] / df_work[denominator_col]\n",
    "        new_features[feat_name] = new_features[feat_name].fillna(0)\n",
    "    \n",
    "    return new_features\n",
    "\n",
    "# Carregar datasets\n",
    "df_dom1 = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio1_BR.parquet'))\n",
    "df_dom2 = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio2_BR_20250417.parquet'))\n",
    "df_dom3 = pd.read_parquet(os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio3_BR_20250417.parquet'))\n",
    "\n",
    "# Denominador\n",
    "denom_col = 'total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003'\n",
    "\n",
    "# Gerar features\n",
    "print(\"\\nProcessando Domicilio 1...\")\n",
    "df_feats_dom1 = generate_relative_features(df_dom1, df_final, denom_col, prefix='pct_dom1_')\n",
    "\n",
    "print(\"\\nProcessando Domicilio 2...\")\n",
    "df_feats_dom2 = generate_relative_features(df_dom2, df_final, denom_col, prefix='pct_dom2_')\n",
    "\n",
    "print(\"\\nProcessando Domicilio 3...\")\n",
    "df_feats_dom3 = generate_relative_features(df_dom3, df_final, denom_col, prefix='pct_dom3_')\n",
    "\n",
    "# Consolidar tudo no df_final\n",
    "print(\"\\nConsolidando features...\")\n",
    "df_final_massive = df_final.copy()\n",
    "\n",
    "if not df_feats_dom1.empty:\n",
    "    df_final_massive = df_final_massive.merge(df_feats_dom1, on='CD_SETOR', how='left')\n",
    "if not df_feats_dom2.empty:\n",
    "    df_final_massive = df_final_massive.merge(df_feats_dom2, on='CD_SETOR', how='left')\n",
    "if not df_feats_dom3.empty:\n",
    "    df_final_massive = df_final_massive.merge(df_feats_dom3, on='CD_SETOR', how='left')\n",
    "\n",
    "print(f\"Shape final: {df_final_massive.shape}\")\n",
    "print(\"Colunas finais (Amostra):\", df_final_massive.columns[-10:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceda8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset massivo salvo em: ../data/silver/censo_2022_agregado_massivo.parquet\n",
      "Total de variáveis: 664\n"
     ]
    }
   ],
   "source": [
    "# Salvar Dataset Massivo\n",
    "output_path_massive = '../data/silver/censo_2022_agregado_massivo.parquet'\n",
    "df_final_massive.to_parquet(output_path_massive, index=False)\n",
    "print(f\"Dataset massivo salvo em: {output_path_massive}\")\n",
    "print(f\"Total de variáveis: {df_final_massive.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8efa9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de Banheiros encontradas: 165\n",
      "domicilios_particulares_permanentes_ocupados_1_banheiro_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00232\n",
      "domicilios_particulares_permanentes_ocupados_2_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00233\n",
      "domicilios_particulares_permanentes_ocupados_3_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00234\n",
      "domicilios_particulares_permanentes_ocupados_4_ou_mais_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00235\n",
      "domicilios_particulares_permanentes_ocupados_apenas_banheiro_de_uso_comum_a_mais_de_um_domicilio_v00236\n",
      "domicilios_particulares_permanentes_ocupados_nao_tinham_banheiro_nem_sanitario_v00238\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_1_banheiro_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00239\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_2_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00240\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_3_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00241\n",
      "domicilios_particulares_permanentes_ocupados_tipo_de_especie_e_casa_4_ou_mais_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v00242\n",
      "Features inteligentes iniciais criadas: media_moradores, densidade_domicilios, area_media_estimada\n"
     ]
    }
   ],
   "source": [
    "# --- FEATURE ENGINEERING INTELIGENTE (PROXIES DE RENDA) ---\n",
    "# O usuário sugeriu indicadores derivados que servem como proxy de renda e qualidade de vida.\n",
    "\n",
    "# 1. Banheiros por Domicílio e por Pessoa\n",
    "# Vamos buscar colunas de banheiros em Domicilio 2\n",
    "cols_banheiros = [c for c in df_dom2.columns if 'banheiro' in c]\n",
    "print(\"Colunas de Banheiros encontradas:\", len(cols_banheiros))\n",
    "# Geralmente tem: '1 banheiro', '2 banheiros', '3 banheiros', etc.\n",
    "# Vamos tentar identificar essas colunas para criar um \"Total de Banheiros Estimado\" do setor\n",
    "# Se tivermos apenas a contagem de domicílios com X banheiros, podemos fazer uma média ponderada.\n",
    "\n",
    "for c in cols_banheiros[:10]:\n",
    "    print(c)\n",
    "\n",
    "# 2. Densidade Domiciliar (Pessoas por Domicílio)\n",
    "# Já temos total de pessoas e total de domicílios no df_final\n",
    "df_final_massive['media_moradores_domicilio'] = df_final_massive['total_de_pessoas_v0001'] / df_final_massive['total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003']\n",
    "\n",
    "# 3. Densidade de Imóveis (Domicílios por km2) - Proxy de Urbanização/Verticalização\n",
    "df_final_massive['densidade_domicilios_km2'] = df_final_massive['total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003'] / df_final_massive['AREA_KM2']\n",
    "\n",
    "# 4. Área Média Estimada por Domicílio (Inverso da densidade, em m2)\n",
    "# 1 km2 = 1.000.000 m2\n",
    "df_final_massive['area_media_estimada_m2'] = (df_final_massive['AREA_KM2'] * 1_000_000) / df_final_massive['total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003']\n",
    "\n",
    "print(\"Features inteligentes iniciais criadas: media_moradores, densidade_domicilios, area_media_estimada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bf3dcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de percentual de banheiros (Tentativa 2): pct_dom2_1_banheiro_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v0232 pct_dom2_2_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v0233 pct_dom2_3_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v0234 pct_dom2_4_ou_mais_banheiros_de_uso_exclusivo_com_chuveiro_e_vaso_sanitario_existentes_no_domicilio_v0235\n",
      "Features de Banheiros criadas com sucesso.\n",
      "Dataset atualizado salvo.\n"
     ]
    }
   ],
   "source": [
    "# Calcular Média Ponderada de Banheiros (Correção de Busca)\n",
    "\n",
    "# As colunas no massive foram renomeadas para 'pct_dom2_...vXXXX'\n",
    "# Mas a função de limpeza removeu 'v0' -> 'v'.\n",
    "# Vamos buscar pelo sufixo do código original ajustado.\n",
    "# v00232 -> v0232 (se removeu v0) ou v232?\n",
    "# A função fez: short_name.replace('v0', 'v')\n",
    "# v00232 -> v0232\n",
    "\n",
    "def get_col_by_suffix(df, suffix):\n",
    "    cols = [c for c in df.columns if c.endswith(suffix)]\n",
    "    return cols[0] if cols else None\n",
    "\n",
    "# Tentar códigos ajustados\n",
    "pct_1_ban = get_col_by_suffix(df_final_massive, 'v0232')\n",
    "pct_2_ban = get_col_by_suffix(df_final_massive, 'v0233')\n",
    "pct_3_ban = get_col_by_suffix(df_final_massive, 'v0234')\n",
    "pct_4_ban = get_col_by_suffix(df_final_massive, 'v0235')\n",
    "\n",
    "print(\"Colunas de percentual de banheiros (Tentativa 2):\", pct_1_ban, pct_2_ban, pct_3_ban, pct_4_ban)\n",
    "\n",
    "if pct_1_ban and pct_2_ban and pct_3_ban and pct_4_ban:\n",
    "    # Média Ponderada de Banheiros por Domicílio\n",
    "    df_final_massive['media_banheiros_domicilio'] = (\n",
    "        (1 * df_final_massive[pct_1_ban]) +\n",
    "        (2 * df_final_massive[pct_2_ban]) +\n",
    "        (3 * df_final_massive[pct_3_ban]) +\n",
    "        (4.5 * df_final_massive[pct_4_ban])\n",
    "    )\n",
    "    \n",
    "    # Banheiros por Pessoa\n",
    "    df_final_massive['banheiros_por_pessoa'] = df_final_massive['media_banheiros_domicilio'] / df_final_massive['media_moradores_domicilio']\n",
    "    \n",
    "    print(\"Features de Banheiros criadas com sucesso.\")\n",
    "else:\n",
    "    print(\"Ainda não encontrou. Vamos listar algumas colunas do massive para debug.\")\n",
    "    print(df_final_massive.columns[100:110].tolist())\n",
    "\n",
    "# Salvar novamente\n",
    "df_final_massive.to_parquet(output_path_massive, index=False)\n",
    "print(\"Dataset atualizado salvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b40692f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicionário de Renda carregado.\n",
      "                   Tema Variável  \\\n",
      "0  Renda do Responsável   V06001   \n",
      "1  Renda do Responsável   V06002   \n",
      "2  Renda do Responsável   V06003   \n",
      "3  Renda do Responsável   V06004   \n",
      "4  Renda do Responsável   V06005   \n",
      "\n",
      "                                           Descrição  \n",
      "0  Pessoas responsáveis em domicílios particulare...  \n",
      "1  Moradores em domicílios particulares permanent...  \n",
      "2  Variância do número de moradores em domicílios...  \n",
      "3  Valor do rendimento nominal médio mensal das p...  \n",
      "4  Variância do rendimento nominal mensal das pes...  \n",
      "Convertendo Agregados_por_setores_renda_responsavel_BR.csv para Parquet...\n",
      "Conversão concluída.\n"
     ]
    }
   ],
   "source": [
    "# --- DADOS DE RENDA ENCONTRADOS ---\n",
    "# O usuário estava certo! Os dados de renda estavam em uma pasta separada no FTP.\n",
    "# Arquivos baixados:\n",
    "# - Agregados_por_setores_renda_responsavel_BR_csv.zip\n",
    "# - dicionario_de_dados_renda_responsavel.xlsx\n",
    "\n",
    "# 1. Carregar Dicionário de Renda\n",
    "dict_renda_path = '../data/raw/dicionario_de_dados_renda_responsavel.xlsx'\n",
    "if os.path.exists(dict_renda_path):\n",
    "    dic_renda = pd.read_excel(dict_renda_path)\n",
    "    print(\"Dicionário de Renda carregado.\")\n",
    "    print(dic_renda.head())\n",
    "else:\n",
    "    print(\"Dicionário de Renda não encontrado.\")\n",
    "\n",
    "# 2. Converter CSV para Parquet (Silver)\n",
    "csv_renda_name = 'Agregados_por_setores_renda_responsavel_BR.csv' # Nome provável após unzip\n",
    "csv_renda_path = os.path.join('../data/raw', csv_renda_name)\n",
    "parquet_renda_path = os.path.join('../data/silver', 'Agregados_por_setores_renda_responsavel_BR.parquet')\n",
    "\n",
    "if os.path.exists(csv_renda_path) and not os.path.exists(parquet_renda_path):\n",
    "    print(f\"Convertendo {csv_renda_name} para Parquet...\")\n",
    "    # Ler CSV (pode ser grande, usar chunks se necessário, mas agregados costumam caber na memória)\n",
    "    # Separador geralmente é ';'\n",
    "    df_renda_raw = pd.read_csv(csv_renda_path, sep=';', dtype={'CD_SETOR': str})\n",
    "    df_renda_raw.to_parquet(parquet_renda_path, index=False)\n",
    "    print(\"Conversão concluída.\")\n",
    "elif os.path.exists(parquet_renda_path):\n",
    "    print(\"Arquivo Parquet de Renda já existe.\")\n",
    "else:\n",
    "    print(f\"Arquivo CSV {csv_renda_name} não encontrado. Verifique o nome extraído.\")\n",
    "    # Listar arquivos para conferir nome\n",
    "    print(os.listdir('../data/raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee9f5e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando colunas de renda...\n",
      "\n",
      "Integrando features de renda ao dataset principal...\n",
      "Renda Avançada integrada.\n",
      "          CD_SETOR  renda_per_capita_sm  cv_renda_desigualdade  \\\n",
      "0  110001505000002             0.732810               1.472526   \n",
      "1  110001505000003             0.656355               0.720637   \n",
      "2  110001505000004             0.525971               0.676889   \n",
      "3  110001505000006             0.510007               0.698288   \n",
      "4  110001505000007             0.619809               0.777750   \n",
      "\n",
      "   moradores_por_responsavel  \n",
      "0                   2.761905  \n",
      "1                   2.673077  \n",
      "2                   2.611765  \n",
      "3                   2.786477  \n",
      "4                   2.570447  \n",
      "Dataset Massivo atualizado com Renda Avançada.\n"
     ]
    }
   ],
   "source": [
    "# --- INTEGRAR RENDA AVANÇADA (Feature Engineering Completo) ---\n",
    "\n",
    "# Carregar dados de renda\n",
    "df_renda = pd.read_parquet(parquet_renda_path)\n",
    "\n",
    "# Mapeamento de colunas baseado no dicionário\n",
    "# V06001: Pessoas responsáveis\n",
    "# V06002: Moradores em domicílios\n",
    "# V06003: Variância do número de moradores\n",
    "# V06004: Rendimento nominal médio mensal das pessoas responsáveis\n",
    "# V06005: Variância do rendimento nominal mensal\n",
    "\n",
    "rename_map = {\n",
    "    'V06001': 'total_responsaveis',\n",
    "    'v06001': 'total_responsaveis',\n",
    "    'V06002': 'total_moradores_renda',\n",
    "    'v06002': 'total_moradores_renda',\n",
    "    'V06003': 'variancia_moradores',\n",
    "    'v06003': 'variancia_moradores',\n",
    "    'V06004': 'rendimento_medio_responsavel',\n",
    "    'v06004': 'rendimento_medio_responsavel',\n",
    "    'V06005': 'variancia_rendimento',\n",
    "    'v06005': 'variancia_rendimento'\n",
    "}\n",
    "\n",
    "df_renda = df_renda.rename(columns=rename_map)\n",
    "\n",
    "# Limpeza e Conversão de Tipos (Tratamento Robusto)\n",
    "print(\"Processando colunas de renda...\")\n",
    "cols_numericas = ['total_responsaveis', 'total_moradores_renda', 'variancia_moradores', 'rendimento_medio_responsavel', 'variancia_rendimento']\n",
    "\n",
    "for col in cols_numericas:\n",
    "    if col in df_renda.columns:\n",
    "        # Converter para string, substituir vírgula, e forçar numérico (erros='coerce' transforma 'X' em NaN)\n",
    "        df_renda[col] = df_renda[col].astype(str).str.replace(',', '.')\n",
    "        df_renda[col] = pd.to_numeric(df_renda[col], errors='coerce')\n",
    "\n",
    "# --- CRIAÇÃO DE FEATURES INTELIGENTES DE RENDA ---\n",
    "\n",
    "# 1. Massa Salarial (Renda Total do Setor Estimada)\n",
    "# Renda Média * Número de Responsáveis\n",
    "df_renda['massa_salarial_total'] = df_renda['rendimento_medio_responsavel'] * df_renda['total_responsaveis']\n",
    "\n",
    "# 2. Renda Per Capita Estimada (Proxy de Poder de Compra Real)\n",
    "# Massa Salarial / Total de Moradores (do arquivo de renda)\n",
    "df_renda['renda_per_capita_estimada'] = df_renda['massa_salarial_total'] / df_renda['total_moradores_renda']\n",
    "\n",
    "# 3. Desvio Padrão da Renda (Volatilidade)\n",
    "# Raiz quadrada da variância\n",
    "df_renda['desvio_padrao_renda'] = df_renda['variancia_rendimento'] ** 0.5\n",
    "\n",
    "# 4. Coeficiente de Variação da Renda (Proxy de Desigualdade)\n",
    "# Desvio Padrão / Média. Quanto maior, maior a desigualdade no setor.\n",
    "df_renda['cv_renda_desigualdade'] = df_renda['desvio_padrao_renda'] / df_renda['rendimento_medio_responsavel']\n",
    "\n",
    "# 5. Carga de Dependência (Moradores por Responsável)\n",
    "# Quantas pessoas dependem de cada renda gerada\n",
    "df_renda['moradores_por_responsavel'] = df_renda['total_moradores_renda'] / df_renda['total_responsaveis']\n",
    "\n",
    "# --- RELATIVIZAÇÃO (SALÁRIOS MÍNIMOS) ---\n",
    "salario_minimo_2022 = 1212.00\n",
    "\n",
    "df_renda['rendimento_medio_responsavel_sm'] = df_renda['rendimento_medio_responsavel'] / salario_minimo_2022\n",
    "df_renda['renda_per_capita_sm'] = df_renda['renda_per_capita_estimada'] / salario_minimo_2022\n",
    "df_renda['massa_salarial_sm'] = df_renda['massa_salarial_total'] / salario_minimo_2022\n",
    "df_renda['desvio_padrao_renda_sm'] = df_renda['desvio_padrao_renda'] / salario_minimo_2022\n",
    "\n",
    "# Selecionar colunas finais para merge\n",
    "cols_to_merge_renda = [\n",
    "    'CD_SETOR', \n",
    "    'rendimento_medio_responsavel', 'rendimento_medio_responsavel_sm',\n",
    "    'renda_per_capita_estimada', 'renda_per_capita_sm',\n",
    "    'massa_salarial_total', 'massa_salarial_sm',\n",
    "    'desvio_padrao_renda', 'cv_renda_desigualdade',\n",
    "    'moradores_por_responsavel'\n",
    "]\n",
    "\n",
    "# Garantir chave\n",
    "df_renda['CD_SETOR'] = df_renda['CD_SETOR'].astype(str)\n",
    "\n",
    "# Merge com o dataset massivo\n",
    "print(\"\\nIntegrando features de renda ao dataset principal...\")\n",
    "# Remover colunas antigas de renda se existirem para evitar duplicatas/conflitos\n",
    "cols_drop = [c for c in cols_to_merge_renda if c in df_final_massive.columns and c != 'CD_SETOR']\n",
    "if cols_drop:\n",
    "    df_final_massive = df_final_massive.drop(columns=cols_drop)\n",
    "\n",
    "df_final_massive = df_final_massive.merge(df_renda[cols_to_merge_renda], on='CD_SETOR', how='left')\n",
    "\n",
    "print(\"Renda Avançada integrada.\")\n",
    "print(df_final_massive[['CD_SETOR', 'renda_per_capita_sm', 'cv_renda_desigualdade', 'moradores_por_responsavel']].head())\n",
    "\n",
    "# Salvar versão atualizada\n",
    "df_final_massive.to_parquet(output_path_massive, index=False)\n",
    "print(\"Dataset Massivo atualizado com Renda Avançada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1080a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra df_renda (com valores válidos):\n",
      "           CD_SETOR V06001 V06002 V06003  rendimento_medio_responsavel  \\\n",
      "23  110001505000051      8     15    0,7                        1700.0   \n",
      "37  110001505000067    100    280   1,41                        4243.0   \n",
      "52  110001525000008      6     27    2,3                        1475.0   \n",
      "53  110001525000013      6     30    2,8                        1004.0   \n",
      "68  110001525000033      5     16    1,7                        1203.0   \n",
      "\n",
      "         V06005  \n",
      "23       310000  \n",
      "37  99330100,71  \n",
      "52       662500  \n",
      "53       122080  \n",
      "68    426702,67  \n",
      "\n",
      "Tipo CD_SETOR df_final_massive: object\n",
      "Tipo CD_SETOR df_renda: object\n",
      "\n",
      "Chaves em comum: 458772\n",
      "Total df_final: 458772\n",
      "Total df_renda: 458772\n"
     ]
    }
   ],
   "source": [
    "# Investigar por que a renda veio NaN (Merge falhou ou dados vazios?)\n",
    "# Verificar se temos dados no df_renda\n",
    "print(\"Amostra df_renda (com valores válidos):\")\n",
    "print(df_renda[df_renda[col_renda].notna()].head())\n",
    "\n",
    "# Verificar tipos de chave\n",
    "print(\"\\nTipo CD_SETOR df_final_massive:\", df_final_massive['CD_SETOR'].dtype)\n",
    "print(\"Tipo CD_SETOR df_renda:\", df_renda['CD_SETOR'].dtype)\n",
    "\n",
    "# Verificar intersecção de chaves\n",
    "common_keys = set(df_final_massive['CD_SETOR']).intersection(set(df_renda['CD_SETOR']))\n",
    "print(f\"\\nChaves em comum: {len(common_keys)}\")\n",
    "print(f\"Total df_final: {len(df_final_massive)}\")\n",
    "print(f\"Total df_renda: {len(df_renda)}\")\n",
    "\n",
    "if len(common_keys) == 0:\n",
    "    print(\"ERRO CRÍTICO: Nenhuma chave em comum. Verifique formatação (zeros à esquerda, etc).\")\n",
    "    print(\"Exemplo Final:\", df_final_massive['CD_SETOR'].iloc[0])\n",
    "    print(\"Exemplo Renda:\", df_renda['CD_SETOR'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd452d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra Raw (Strings):\n",
      "0    2453,03\n",
      "1    2126,44\n",
      "2    1664,94\n",
      "3     1722,4\n",
      "4    1930,94\n",
      "5    3182,32\n",
      "6    3477,32\n",
      "7    2315,18\n",
      "8    3565,82\n",
      "9    5100,07\n",
      "Name: V06004, dtype: object\n",
      "Exemplo de valor: '2453,03' (Tipo: <class 'str'>)\n",
      "Detectado uso de vírgula como decimal. Corrigindo...\n",
      "Correção aplicada.\n",
      "          CD_SETOR  renda_media_sm\n",
      "0  110001505000002        2.023952\n",
      "1  110001505000003        1.754488\n",
      "2  110001505000004        1.373713\n",
      "3  110001505000006        1.421122\n",
      "4  110001505000007        1.593185\n",
      "Percentual de nulos em renda: 0.02014290322861901\n"
     ]
    }
   ],
   "source": [
    "# Debug: Verificar formato original da coluna de renda (Correção com numpy)\n",
    "import numpy as np\n",
    "\n",
    "# Recarregar raw para checar strings\n",
    "df_renda_raw_check = pd.read_parquet(parquet_renda_path)\n",
    "col_raw = 'V06004' if 'V06004' in df_renda_raw_check.columns else 'v06004'\n",
    "\n",
    "print(\"Amostra Raw (Strings):\")\n",
    "print(df_renda_raw_check[col_raw].head(10))\n",
    "\n",
    "# Verificar se tem vírgula\n",
    "sample_val = df_renda_raw_check[col_raw].dropna().iloc[0]\n",
    "print(f\"Exemplo de valor: '{sample_val}' (Tipo: {type(sample_val)})\")\n",
    "\n",
    "if isinstance(sample_val, str) and ',' in sample_val:\n",
    "    print(\"Detectado uso de vírgula como decimal. Corrigindo...\")\n",
    "    \n",
    "    # Recarregar e corrigir\n",
    "    df_renda = pd.read_parquet(parquet_renda_path)\n",
    "    df_renda = df_renda.rename(columns={col_raw: 'rendimento_medio_responsavel'})\n",
    "    \n",
    "    # Substituir vírgula por ponto e converter\n",
    "    # replace('X', np.nan) deve ser feito com cuidado em strings\n",
    "    df_renda['rendimento_medio_responsavel'] = df_renda['rendimento_medio_responsavel'].astype(str).str.replace(',', '.')\n",
    "    \n",
    "    # Tratar 'X' ou outros não numéricos via coerce\n",
    "    df_renda['rendimento_medio_responsavel'] = pd.to_numeric(df_renda['rendimento_medio_responsavel'], errors='coerce')\n",
    "    \n",
    "    # Refazer o merge\n",
    "    df_final_massive = df_final_massive.drop(columns=['rendimento_medio_responsavel', 'renda_media_sm'], errors='ignore')\n",
    "    df_final_massive['CD_SETOR'] = df_final_massive['CD_SETOR'].astype(str)\n",
    "    df_renda['CD_SETOR'] = df_renda['CD_SETOR'].astype(str)\n",
    "    \n",
    "    df_final_massive = df_final_massive.merge(df_renda[['CD_SETOR', 'rendimento_medio_responsavel']], on='CD_SETOR', how='left')\n",
    "    df_final_massive['renda_media_sm'] = df_final_massive['rendimento_medio_responsavel'] / 1212.00\n",
    "    \n",
    "    print(\"Correção aplicada.\")\n",
    "    print(df_final_massive[['CD_SETOR', 'renda_media_sm']].head())\n",
    "    print(\"Percentual de nulos em renda:\", df_final_massive['renda_media_sm'].isna().mean())\n",
    "    \n",
    "    # Salvar\n",
    "    df_final_massive.to_parquet(output_path_massive, index=False)\n",
    "else:\n",
    "    print(\"Formato parece correto ou não é string com vírgula.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad2a6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Agregados_por_setores_entorno_domicílios_BR.csv...\n",
      "Convertendo colunas numéricas...\n",
      "Salvando Parquet...\n",
      "Conversão concluída.\n",
      "Entorno carregado. Shape: (340965, 36)\n",
      "Colunas (Amostra): ['CD_SETOR', 'V05000', 'V05001', 'V05002', 'V05003', 'V05004', 'V05005', 'V05006', 'V05007', 'V05008']\n",
      "Dtypes (Amostra): CD_SETOR     object\n",
      "V05000      float64\n",
      "V05001      float64\n",
      "V05002      float64\n",
      "V05003      float64\n",
      "dtype: object\n",
      "\n",
      "Processando Entorno...\n",
      "Usando denominador do Básico (pode haver distorção se o universo for diferente)\n",
      "Gerando 35 novas features relativas...\n",
      "\n",
      "Consolidando Entorno...\n",
      "Shape final: (458772, 706)\n"
     ]
    }
   ],
   "source": [
    "# --- DADOS DE ENTORNO (URBANISMO) ---\n",
    "# O usuário perguntou se faltava algo. Faltava o \"Entorno\"!\n",
    "# Arquivos baixados:\n",
    "# - Agregados_por_setores_entorno_domicílios_BR.csv (Características do entorno dos domicílios)\n",
    "# - Agregados_por_setores_entorno_faces_BR.csv (Características das faces de quadra)\n",
    "# - Agregados_por_setores_entorno_moradores_BR.csv (Moradores afetados pelas características)\n",
    "\n",
    "# Vamos focar no arquivo de Domicílios do Entorno, pois cruza melhor com nosso dataset de Domicílios.\n",
    "# Ele deve conter: Pavimentação, Iluminação, Calçada, Bueiro, Arborização, Esgoto a céu aberto, Lixo acumulado.\n",
    "\n",
    "csv_entorno_name = 'Agregados_por_setores_entorno_domicílios_BR.csv'\n",
    "csv_entorno_path = os.path.join('../data/raw', csv_entorno_name)\n",
    "parquet_entorno_path = os.path.join('../data/silver', 'Agregados_por_setores_entorno_domicilios_BR.parquet')\n",
    "\n",
    "if os.path.exists(csv_entorno_path):\n",
    "    print(f\"Processando {csv_entorno_name}...\")\n",
    "    # Ler CSV com separador ; e decimal , (se possível, mas as vezes o pandas não pega direto se tiver aspas ou algo assim)\n",
    "    # Vamos ler tudo como string primeiro para garantir e depois converter\n",
    "    df_entorno_raw = pd.read_csv(csv_entorno_path, sep=';', dtype=str)\n",
    "    \n",
    "    # Renomear CD_setor para CD_SETOR se necessário\n",
    "    if 'CD_setor' in df_entorno_raw.columns:\n",
    "        df_entorno_raw = df_entorno_raw.rename(columns={'CD_setor': 'CD_SETOR'})\n",
    "    \n",
    "    # Converter colunas numéricas\n",
    "    print(\"Convertendo colunas numéricas...\")\n",
    "    for col in df_entorno_raw.columns:\n",
    "        if col != 'CD_SETOR':\n",
    "            # Substituir vírgula por ponto e converter\n",
    "            # Usar errors='coerce' para transformar 'X' ou outros erros em NaN\n",
    "            df_entorno_raw[col] = pd.to_numeric(df_entorno_raw[col].str.replace(',', '.'), errors='coerce')\n",
    "            \n",
    "    print(\"Salvando Parquet...\")\n",
    "    df_entorno_raw.to_parquet(parquet_entorno_path, index=False)\n",
    "    print(\"Conversão concluída.\")\n",
    "\n",
    "elif os.path.exists(parquet_entorno_path):\n",
    "    print(\"Arquivo Parquet de Entorno já existe.\")\n",
    "else:\n",
    "    print(f\"Arquivo CSV {csv_entorno_name} não encontrado.\")\n",
    "\n",
    "# Carregar Entorno\n",
    "if os.path.exists(parquet_entorno_path):\n",
    "    df_entorno = pd.read_parquet(parquet_entorno_path)\n",
    "    print(\"Entorno carregado. Shape:\", df_entorno.shape)\n",
    "    print(\"Colunas (Amostra):\", df_entorno.columns[:10].tolist())\n",
    "    print(\"Dtypes (Amostra):\", df_entorno.dtypes[:5])\n",
    "    \n",
    "    # Gerar features relativas do Entorno\n",
    "    # Denominador: Total de Domicílios Particulares Permanentes (V0001 do Entorno?)\n",
    "    # Vamos checar se tem um total.\n",
    "    # Geralmente V0001 é o total.\n",
    "    \n",
    "    print(\"\\nProcessando Entorno...\")\n",
    "    # Usar o denominador do Basico para manter consistência (domicílios do setor)\n",
    "    # Mas o Entorno pode ter um universo diferente (domicílios em face de quadra etc).\n",
    "    # Vamos usar o denominador do próprio dataset se possível, ou o do basico.\n",
    "    # V0001 costuma ser o total de domicílios investigados no entorno.\n",
    "    \n",
    "    denom_entorno = 'V0001' # Hipótese\n",
    "    if denom_entorno in df_entorno.columns:\n",
    "        print(f\"Usando denominador interno: {denom_entorno}\")\n",
    "        df_feats_entorno = generate_relative_features(df_entorno, df_entorno, denom_entorno, prefix='pct_entorno_')\n",
    "    else:\n",
    "        print(\"Usando denominador do Básico (pode haver distorção se o universo for diferente)\")\n",
    "        df_feats_entorno = generate_relative_features(df_entorno, df_final_massive, denom_col, prefix='pct_entorno_')\n",
    "    \n",
    "    # Merge\n",
    "    print(\"\\nConsolidando Entorno...\")\n",
    "    # Remover colunas duplicadas se houver\n",
    "    cols_to_merge = [c for c in df_feats_entorno.columns if c not in df_final_massive.columns or c == 'CD_SETOR']\n",
    "    df_final_massive = df_final_massive.merge(df_feats_entorno[cols_to_merge], on='CD_SETOR', how='left')\n",
    "    print(f\"Shape final: {df_final_massive.shape}\")\n",
    "else:\n",
    "    print(\"Pular Entorno (não carregado).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1e4cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- APLICANDO CAMADA EXPERT ---\n",
      "Trazendo features atualizadas para o dataset massivo: ['pct_agua_rede']\n",
      "Índice de Diversidade Racial calculado.\n",
      "Índice de Saneamento calculado com: ['pct_agua_rede', 'pct_esgoto_rede', 'pct_lixo_coletado']\n",
      "Índice de Potencial de Consumo calculado.\n",
      "Camada Expert aplicada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# --- FEATURE ENGINEERING: CAMADA EXPERT (\"Dono do Dado\") ---\n",
    "# Criação de índices compostos e métricas avançadas para maximizar o valor analítico.\n",
    "# Objetivo: Transformar dados brutos em inteligência de negócio.\n",
    "\n",
    "print(\"\\n--- APLICANDO CAMADA EXPERT ---\")\n",
    "\n",
    "# Garantir que as features de saneamento recém-calculadas (pct_agua_rede) estejam no df_final_massive\n",
    "# O df_final foi atualizado no passo anterior, mas o df_final_massive é uma cópia anterior.\n",
    "# Vamos trazer as colunas faltantes do df_final para o df_final_massive\n",
    "cols_to_bring = ['pct_agua_rede', 'pct_esgoto_rede', 'pct_lixo_coletado']\n",
    "cols_to_merge_expert = [c for c in cols_to_bring if c in df_final.columns and c not in df_final_massive.columns]\n",
    "\n",
    "if cols_to_merge_expert:\n",
    "    print(f\"Trazendo features atualizadas para o dataset massivo: {cols_to_merge_expert}\")\n",
    "    df_final_massive = df_final_massive.merge(df_final[['CD_SETOR'] + cols_to_merge_expert], on='CD_SETOR', how='left')\n",
    "\n",
    "# 1. DEMOGRAFIA AVANÇADA\n",
    "# Razão de Dependência: (Jovens + Idosos) / Adultos\n",
    "# Mede a pressão sobre a população economicamente ativa.\n",
    "# Se a população adulta for zero (improvável, mas possível em áreas industriais), usamos 1e-6.\n",
    "df_final_massive['razao_dependencia'] = (df_final_massive['pop_0_19'] + df_final_massive['pop_70_plus']) / (df_final_massive['pop_20_69'] + 1e-6)\n",
    "\n",
    "# Índice de Envelhecimento: Idosos / Jovens\n",
    "# Indica a transição demográfica. > 1 indica população envelhecida.\n",
    "df_final_massive['indice_envelhecimento'] = df_final_massive['pop_70_plus'] / (df_final_massive['pop_0_19'] + 1e-6)\n",
    "\n",
    "# 2. DIVERSIDADE RACIAL (Índice de Simpson)\n",
    "# Mede a heterogeneidade do setor. 1 - soma(proporção^2).\n",
    "# Valores próximos de 1 indicam alta diversidade (mistura de grupos).\n",
    "# Valores próximos de 0 indicam homogeneidade (domínio de um único grupo).\n",
    "\n",
    "cols_raca_pct = ['pct_branca', 'pct_preta', 'pct_parda']\n",
    "# Verificar quais colunas existem no dataset\n",
    "existing_raca_cols = [c for c in cols_raca_pct if c in df_final_massive.columns]\n",
    "\n",
    "if len(existing_raca_cols) >= 1:\n",
    "    # Calcular soma dos quadrados das raças conhecidas\n",
    "    sum_sq = df_final_massive[existing_raca_cols].pow(2).sum(axis=1)\n",
    "    \n",
    "    # Estimar o \"Outros\" (Amarela + Indígena + Ignorado) para completar 100%\n",
    "    pct_outros = 1 - df_final_massive[existing_raca_cols].sum(axis=1)\n",
    "    pct_outros = pct_outros.clip(lower=0) # Evitar negativos\n",
    "    \n",
    "    # Adicionar quadrado dos outros\n",
    "    sum_sq += pct_outros**2\n",
    "    \n",
    "    df_final_massive['indice_diversidade_racial'] = 1 - sum_sq\n",
    "    print(\"Índice de Diversidade Racial calculado.\")\n",
    "\n",
    "# 3. ÍNDICE DE SANEAMENTO BÁSICO (ISB)\n",
    "# Média aritmética de Água, Esgoto e Lixo.\n",
    "# Um score de 0 a 1 que resume a infraestrutura básica.\n",
    "cols_san = ['pct_agua_rede', 'pct_esgoto_rede', 'pct_lixo_coletado']\n",
    "existing_san_cols = [c for c in cols_san if c in df_final_massive.columns]\n",
    "\n",
    "if existing_san_cols:\n",
    "    df_final_massive['indice_saneamento_basico'] = df_final_massive[existing_san_cols].mean(axis=1)\n",
    "    \n",
    "    # Indicador de Precariedade Sanitária (Binário)\n",
    "    # Consideramos precário se o índice for menor que 0.5 (menos da metade dos serviços)\n",
    "    df_final_massive['indicador_precariedade_sanitaria'] = (df_final_massive['indice_saneamento_basico'] < 0.5).astype(int)\n",
    "    print(f\"Índice de Saneamento calculado com: {existing_san_cols}\")\n",
    "\n",
    "# 4. POTENCIAL DE CONSUMO (Proxy)\n",
    "# Combina Renda (Poder de Compra) com Densidade Demográfica (Volume de Pessoas).\n",
    "# Onde tem muita gente E renda razoável = Hotspot para comércio.\n",
    "if 'renda_per_capita_sm' in df_final_massive.columns:\n",
    "    # Usamos log na densidade para suavizar extremos (setores verticais vs rurais)\n",
    "    log_densidade = np.log1p(df_final_massive['densidade_demografica'])\n",
    "    \n",
    "    # Potencial = Renda * Volume\n",
    "    df_final_massive['indice_potencial_consumo'] = df_final_massive['renda_per_capita_sm'] * log_densidade\n",
    "    print(\"Índice de Potencial de Consumo calculado.\")\n",
    "\n",
    "print(\"Camada Expert aplicada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INTEGRAR MORTALIDADE E ESTRUTURA FAMILIAR (Camada Expert Final) ---\n",
    "\n",
    "print(\"\\n--- PROCESSANDO MORTALIDADE E PARENTESCO ---\")\n",
    "\n",
    "# 1. MORTALIDADE (Óbitos)\n",
    "# Arquivo: Agregados_por_setores_obitos_BR.csv\n",
    "# V01224: Domicílios com pessoa falecida\n",
    "# V01226: Óbitos Masculinos\n",
    "# V01227: Óbitos Femininos\n",
    "\n",
    "csv_obitos_path = os.path.join('../data/raw', 'Agregados_por_setores_obitos_BR.csv')\n",
    "parquet_obitos_path = os.path.join('../data/silver', 'Agregados_por_setores_obitos_BR.parquet')\n",
    "\n",
    "if os.path.exists(csv_obitos_path) and not os.path.exists(parquet_obitos_path):\n",
    "    print(\"Convertendo Óbitos para Parquet...\")\n",
    "    df_obitos_raw = pd.read_csv(csv_obitos_path, sep=';', dtype={'CD_SETOR': str})\n",
    "    df_obitos_raw.to_parquet(parquet_obitos_path, index=False)\n",
    "\n",
    "if os.path.exists(parquet_obitos_path):\n",
    "    df_obitos = pd.read_parquet(parquet_obitos_path)\n",
    "    \n",
    "    # Garantir chave\n",
    "    if 'CD_SETOR' in df_obitos.columns:\n",
    "        df_obitos['CD_SETOR'] = df_obitos['CD_SETOR'].astype(str)\n",
    "        \n",
    "        # Features de Mortalidade\n",
    "        if 'V01226' in df_obitos.columns and 'V01227' in df_obitos.columns:\n",
    "            df_obitos['total_obitos'] = df_obitos['V01226'] + df_obitos['V01227']\n",
    "            \n",
    "            # Merge\n",
    "            df_final_massive = df_final_massive.merge(df_obitos[['CD_SETOR', 'total_obitos']], on='CD_SETOR', how='left')\n",
    "            \n",
    "            # Calcular Taxa (por 1000 habitantes)\n",
    "            df_final_massive['taxa_mortalidade_1000'] = (df_final_massive['total_obitos'] / df_final_massive['total_de_pessoas_v0001']) * 1000\n",
    "            df_final_massive['taxa_mortalidade_1000'] = df_final_massive['taxa_mortalidade_1000'].fillna(0)\n",
    "            \n",
    "            print(\"Features de Mortalidade calculadas.\")\n",
    "        else:\n",
    "            print(\"Colunas de óbitos (V01226/V01227) não encontradas.\")\n",
    "    else:\n",
    "        print(\"CD_SETOR ausente em Óbitos.\")\n",
    "\n",
    "# 2. ESTRUTURA FAMILIAR (Parentesco)\n",
    "# Arquivo: Agregados_por_setores_parentesco_BR.csv\n",
    "# V01042: Pessoa responsável pelo domicílio\n",
    "# V01043: Cônjuge (Sexo Diferente)\n",
    "# V01044: Cônjuge (Mesmo Sexo)\n",
    "# V01046: Filho somente do responsável (Proxy Monoparental)\n",
    "# V01049: Pais/Sogros\n",
    "# V01051: Netos\n",
    "\n",
    "csv_parentesco_path = os.path.join('../data/raw', 'Agregados_por_setores_parentesco_BR.csv')\n",
    "parquet_parentesco_path = os.path.join('../data/silver', 'Agregados_por_setores_parentesco_BR.parquet')\n",
    "\n",
    "if os.path.exists(csv_parentesco_path) and not os.path.exists(parquet_parentesco_path):\n",
    "    print(\"Convertendo Parentesco para Parquet...\")\n",
    "    df_par_raw = pd.read_csv(csv_parentesco_path, sep=';', dtype={'CD_SETOR': str})\n",
    "    df_par_raw.to_parquet(parquet_parentesco_path, index=False)\n",
    "\n",
    "if os.path.exists(parquet_parentesco_path):\n",
    "    df_par = pd.read_parquet(parquet_parentesco_path)\n",
    "    \n",
    "    if 'CD_SETOR' in df_par.columns:\n",
    "        df_par['CD_SETOR'] = df_par['CD_SETOR'].astype(str)\n",
    "        \n",
    "        # Calcular Features\n",
    "        # Taxa de Conjugalidade (Casais / Responsáveis)\n",
    "        df_par['total_conjuges'] = df_par['V01043'] + df_par['V01044']\n",
    "        df_par['taxa_conjugalidade'] = df_par['total_conjuges'] / df_par['V01042']\n",
    "        \n",
    "        # Proxy Monoparental (Filhos só do responsável / Responsáveis)\n",
    "        df_par['taxa_monoparental_proxy'] = df_par['V01046'] / df_par['V01042']\n",
    "        \n",
    "        # Coabitação Multigeracional (Pais + Netos / Responsáveis)\n",
    "        df_par['taxa_multigeracional'] = (df_par['V01049'] + df_par['V01051']) / df_par['V01042']\n",
    "        \n",
    "        # Selecionar colunas\n",
    "        cols_par = ['CD_SETOR', 'taxa_conjugalidade', 'taxa_monoparental_proxy', 'taxa_multigeracional']\n",
    "        \n",
    "        # Merge\n",
    "        df_final_massive = df_final_massive.merge(df_par[cols_par], on='CD_SETOR', how='left')\n",
    "        print(\"Features de Parentesco (Conjugalidade, Monoparental, Multigeracional) calculadas.\")\n",
    "\n",
    "# 3. DOMICÍLIOS UNIPESSOAIS (Do Domicilio 1)\n",
    "# V00017: Domicílios com 1 morador\n",
    "path_dom1 = os.path.join(data_dir, 'Agregados_por_setores_caracteristicas_domicilio1_BR.parquet')\n",
    "if os.path.exists(path_dom1):\n",
    "    df_dom1 = pd.read_parquet(path_dom1)\n",
    "    if 'CD_SETOR' not in df_dom1.columns:\n",
    "        if 'CD_setor' in df_dom1.columns: df_dom1 = df_dom1.rename(columns={'CD_setor': 'CD_SETOR'})\n",
    "        elif 'index' in df_dom1.columns: df_dom1 = df_dom1.rename(columns={'index': 'CD_SETOR'})\n",
    "    \n",
    "    if 'CD_SETOR' in df_dom1.columns:\n",
    "        df_dom1['CD_SETOR'] = df_dom1['CD_SETOR'].astype(str)\n",
    "        col_unipessoal = find_col_by_code(df_dom1, 'v00017')\n",
    "        \n",
    "        if col_unipessoal:\n",
    "            df_final_massive = df_final_massive.merge(df_dom1[['CD_SETOR', col_unipessoal]], on='CD_SETOR', how='left')\n",
    "            denom = df_final_massive['total_de_domicilios_particulares_dppo_dppv_dppuo_dpio_v0003']\n",
    "            df_final_massive['pct_domicilios_unipessoais'] = df_final_massive[col_unipessoal] / denom\n",
    "            print(\"Feature % Domicílios Unipessoais calculada.\")\n",
    "\n",
    "# Salvar Atualização Final\n",
    "df_final_massive.to_parquet(output_path_massive, index=False)\n",
    "print(f\"Dataset Massivo Final salvo com {df_final_massive.shape[1]} colunas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef3983de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando dataset final em: ../data/gold\\censo_2022_features_final.parquet\n",
      "\n",
      "--- RESUMO FINAL ---\n",
      "Total de Setores: 458772\n",
      "Total de Features: 721\n",
      "\n",
      "Grupos de Features:\n",
      "- Identificação: 4\n",
      "- Demografia (Idade/Sexo): 94\n",
      "- Cor/Raça: 185\n",
      "- Saneamento/Infra: 426\n",
      "- Renda (Completa): 9\n",
      "- Entorno (Urbanismo): 35\n",
      "- Outras (Massive FE): 621 (aprox)\n",
      "\n",
      "Processo concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- SALVAMENTO FINAL ---\n",
    "\n",
    "output_path_gold = os.path.join('../data/gold', 'censo_2022_features_final.parquet')\n",
    "os.makedirs(os.path.dirname(output_path_gold), exist_ok=True)\n",
    "\n",
    "print(f\"Salvando dataset final em: {output_path_gold}\")\n",
    "df_final_massive.to_parquet(output_path_gold, index=False)\n",
    "\n",
    "print(\"\\n--- RESUMO FINAL ---\")\n",
    "print(f\"Total de Setores: {df_final_massive.shape[0]}\")\n",
    "print(f\"Total de Features: {df_final_massive.shape[1]}\")\n",
    "print(\"\\nGrupos de Features:\")\n",
    "cols = df_final_massive.columns\n",
    "print(f\"- Identificação: {len([c for c in cols if c in ['CD_SETOR', 'NM_MUN', 'NM_UF', 'AREA_KM2']])}\")\n",
    "print(f\"- Demografia (Idade/Sexo): {len([c for c in cols if 'idade' in c or 'homem' in c or 'mulher' in c])}\")\n",
    "print(f\"- Cor/Raça: {len([c for c in cols if 'cor_ou_raca' in c])}\")\n",
    "print(f\"- Saneamento/Infra: {len([c for c in cols if 'agua' in c or 'esgoto' in c or 'lixo' in c or 'banheiro' in c])}\")\n",
    "print(f\"- Renda (Completa): {len([c for c in cols if 'renda' in c or 'rendimento' in c or 'salario' in c or 'massa' in c])}\")\n",
    "print(f\"- Entorno (Urbanismo): {len([c for c in cols if 'entorno' in c])}\")\n",
    "print(f\"- Outras (Massive FE): {len(cols) - 100} (aprox)\")\n",
    "\n",
    "print(\"\\nProcesso concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
